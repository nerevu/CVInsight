{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a85aa9",
   "metadata": {},
   "source": [
    "# CVInsight Step-by-Step Tutorial\n",
    "\n",
    "Welcome to CVInsight! This comprehensive tutorial will walk you through resume analysis step-by-step, perfect for learning how the system works and understanding each component.\n",
    "\n",
    "## üéØ **Learning Objectives**\n",
    "- Understand CVInsight's unified extractor architecture\n",
    "- Learn to analyze individual resumes in detail\n",
    "- Master job-specific relevance scoring\n",
    "- Process multiple resumes systematically\n",
    "- Export and interpret results\n",
    "\n",
    "## üë• **Who This Is For**\n",
    "- New users learning CVInsight\n",
    "- Developers integrating resume analysis\n",
    "- HR professionals understanding candidate scoring\n",
    "- Students learning NLP and resume processing\n",
    "\n",
    "## üìö **Tutorial Structure**\n",
    "1. **Setup & Initialization** - Get CVInsight running\n",
    "2. **Single Resume Analysis** - Deep dive into one resume\n",
    "3. **Understanding the Fields** - Explore all 21 analysis fields\n",
    "4. **Job Relevance Scoring** - How job descriptions affect results\n",
    "5. **Batch Processing** - Handle multiple resumes systematically\n",
    "6. **Results Interpretation** - Make sense of the data\n",
    "7. **Integration & Export** - Use results in your applications\n",
    "\n",
    "## üîß **External Repository Integration**\n",
    "```bash\n",
    "# Clone CVInsight to your projects directory\n",
    "git clone https://github.com/your-username/CVInsight.git\n",
    "\n",
    "# Install dependencies\n",
    "cd CVInsight\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "export OPEN_AI_API_KEY=\"your-key-here\"\n",
    "\n",
    "# Now you can use CVInsight from any notebook!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1679f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STEP 1: SETTING UP CVINSIGHT\n",
      "==================================================\n",
      "üìÅ CVInsight path: /Users/samcelarek/Documents/CVInsight\n",
      "‚úÖ CVInsight successfully imported!\n",
      "üì¶ Available functions:\n",
      "   ‚Ä¢ initialize_client() - Set up the AI client\n",
      "   ‚Ä¢ find_resumes() - Discover resume files\n",
      "   ‚Ä¢ parse_single_resume() - Analyze one resume\n",
      "   ‚Ä¢ parse_many_resumes() - Batch process multiple resumes\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup and Imports\n",
    "print(\"üöÄ STEP 1: SETTING UP CVINSIGHT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CVInsight to your Python path\n",
    "# Adjust this path to where you cloned CVInsight\n",
    "CVINSIGHT_PATH = \"/Users/samcelarek/Documents/CVInsight\"\n",
    "if CVINSIGHT_PATH not in sys.path:\n",
    "    sys.path.insert(0, CVINSIGHT_PATH)\n",
    "\n",
    "print(f\"üìÅ CVInsight path: {CVINSIGHT_PATH}\")\n",
    "\n",
    "# Import CVInsight functions\n",
    "try:\n",
    "    from cvinsight.notebook_utils import (\n",
    "        initialize_client,\n",
    "        find_resumes,\n",
    "        parse_single_resume,\n",
    "        parse_many_resumes\n",
    "    )\n",
    "    print(\"‚úÖ CVInsight successfully imported!\")\n",
    "    print(\"üì¶ Available functions:\")\n",
    "    print(\"   ‚Ä¢ initialize_client() - Set up the AI client\")\n",
    "    print(\"   ‚Ä¢ find_resumes() - Discover resume files\")\n",
    "    print(\"   ‚Ä¢ parse_single_resume() - Analyze one resume\")\n",
    "    print(\"   ‚Ä¢ parse_many_resumes() - Batch process multiple resumes\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"‚ùå Import error: {e}\")\n",
    "    print(\"üí° Make sure CVInsight is cloned and the path is correct!\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8ea860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß STEP 2: INITIALIZING THE AI CLIENT\n",
      "==================================================\n",
      "üîÑ Initializing CVInsight client...\n",
      "üìä Found 6 extractors:\n",
      "   ‚Ä¢ profile_extractor\n",
      "   ‚Ä¢ skills_extractor\n",
      "   ‚Ä¢ education_extractor\n",
      "   ‚Ä¢ experience_extractor\n",
      "   ‚Ä¢ yoe_extractor\n",
      "   ‚Ä¢ extended_analysis_extractor\n",
      "\n",
      "‚úÖ Unified extractor is ready!\n",
      "üöÄ This extractor provides all 21 analysis fields in a single call\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize the CVInsight Client\n",
    "print(\"\\nüîß STEP 2: INITIALIZING THE AI CLIENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get your OpenAI API key\n",
    "api_key = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"üîë API key not found in environment variables\")\n",
    "    print(\"üí° You can either:\")\n",
    "    print(\"   1. Set it as an environment variable: export OPEN_AI_API_KEY='your-key'\")\n",
    "    print(\"   2. Enter it manually below\")\n",
    "    api_key = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"üîÑ Initializing CVInsight client...\")\n",
    "\n",
    "# Initialize the client\n",
    "client = initialize_client(api_key=api_key)\n",
    "\n",
    "# Check what extractors are available\n",
    "extractors = list(client._plugin_manager.extractors.keys())\n",
    "print(f\"üìä Found {len(extractors)} extractors:\")\n",
    "for extractor in extractors:\n",
    "    print(f\"   ‚Ä¢ {extractor}\")\n",
    "\n",
    "# Verify the unified extractor is available\n",
    "if 'extended_analysis_extractor' in extractors:\n",
    "    print(\"\\n‚úÖ Unified extractor is ready!\")\n",
    "    print(\"üöÄ This extractor provides all 21 analysis fields in a single call\")\n",
    "else:\n",
    "    print(\"\\n‚ùå Unified extractor not found!\")\n",
    "    print(\"üí° Make sure you have the latest CVInsight version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fda61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìÅ STEP 3: FINDING RESUME FILES\n",
      "========================================\n",
      "üîç Searching for resumes in: /Users/samcelarek/Documents/CVInsight/Resumes\n",
      "üìÑ Found 21 resume files\n",
      "\n",
      "üìã Resume files discovered:\n",
      "    1. 2023-08-28 - Wesley Ordonez Resume Wesley Ordonez 2023 (Data Analytics).pdf (85.0 KB)\n",
      "    2. 2023-08-20 - Weihao Chen Resume Resume_Weihao Chen.pdf (95.4 KB)\n",
      "    3. 2023-08-26 - Akhil Bukkapuram Resume Akhil_ds.pdf (200.7 KB)\n",
      "    4. 2023-08-28 - Brian Warras Resume BrianWarras.pdf (236.5 KB)\n",
      "    5. 2023-08-22 - Stefani Sanchez Resume Stefani Sanchez Resume.pdf (61.6 KB)\n",
      "    6. Gaurav_Kumar.pdf (309.0 KB)\n",
      "    7. 2023-08-25 - Ka Yee Yuen Resume Resume_Claire-Yuen.pdf (91.9 KB)\n",
      "    8. 2023-08-16 - Niveditha Channapatna Raju Resume nivedithacr_resume.pdf (74.2 KB)\n",
      "    9. 2023-08-20 - Bryan Aguilar Resume Bryan's Resume.pdf (80.5 KB)\n",
      "   10. 2023-08-23 - Eliana Mugar Resume Eliana Mugar_NLPCS.pdf (94.6 KB)\n",
      "   ... and 11 more files\n",
      "\n",
      "üìä Supported formats: PDF, DOC, DOCX\n",
      "üí° CVInsight will extract text from all these formats automatically\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Discover Resume Files\n",
    "print(\"\\nüìÅ STEP 3: FINDING RESUME FILES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Set your resume directory path\n",
    "# Adjust this to where your resume files are located\n",
    "resume_dir = \"/Users/samcelarek/Documents/CVInsight/Resumes\"  # Change this path!\n",
    "\n",
    "print(f\"üîç Searching for resumes in: {resume_dir}\")\n",
    "\n",
    "# Find all resume files\n",
    "resume_paths = find_resumes(resume_dir)\n",
    "\n",
    "print(f\"üìÑ Found {len(resume_paths)} resume files\")\n",
    "\n",
    "if resume_paths:\n",
    "    print(\"\\nüìã Resume files discovered:\")\n",
    "    for i, path in enumerate(resume_paths[:10], 1):  # Show first 10\n",
    "        filename = os.path.basename(path)\n",
    "        file_size = os.path.getsize(path) / 1024  # Size in KB\n",
    "        print(f\"   {i:2d}. {filename} ({file_size:.1f} KB)\")\n",
    "    \n",
    "    if len(resume_paths) > 10:\n",
    "        print(f\"   ... and {len(resume_paths) - 10} more files\")\n",
    "    \n",
    "    print(f\"\\nüìä Supported formats: PDF, DOC, DOCX\")\n",
    "    print(f\"üí° CVInsight will extract text from all these formats automatically\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No resume files found!\")\n",
    "    print(\"üí° Make sure to:\")\n",
    "    print(\"   ‚Ä¢ Check the resume_dir path is correct\")\n",
    "    print(\"   ‚Ä¢ Add some PDF, DOC, or DOCX resume files\")\n",
    "    print(\"   ‚Ä¢ Ensure the files are readable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d6dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìã STEP 4: DEFINING THE JOB DESCRIPTION\n",
      "==================================================\n",
      "üìù Job description created (1388 characters)\n",
      "\n",
      "üéØ Job Focus: Data Scientist - Healthcare Technology\n",
      "üí° Key requirements: Python, R, ML, Healthcare data, 3+ years experience\n",
      "üìÖ Analysis date: 2025-05-29\n",
      "\n",
      "‚úÖ Job description ready for relevance scoring!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create a Job Description\n",
    "print(\"\\nüìã STEP 4: DEFINING THE JOB DESCRIPTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a detailed job description\n",
    "# This will be used to calculate relevance scores\n",
    "job_description = \"\"\"\n",
    "Data Scientist Position - Healthcare Technology\n",
    "\n",
    "We are seeking a talented Data Scientist to join our healthcare technology team. The ideal candidate will have:\n",
    "\n",
    "Required Qualifications:\n",
    "‚Ä¢ Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or related field\n",
    "‚Ä¢ 3+ years of experience in data analysis and machine learning\n",
    "‚Ä¢ Strong programming skills in Python and R\n",
    "‚Ä¢ Experience with SQL and database management\n",
    "‚Ä¢ Knowledge of statistical analysis and hypothesis testing\n",
    "‚Ä¢ Proficiency with machine learning libraries (scikit-learn, pandas, numpy)\n",
    "‚Ä¢ Experience with data visualization tools (matplotlib, seaborn, Tableau)\n",
    "\n",
    "Preferred Qualifications:\n",
    "‚Ä¢ Healthcare or medical data analysis experience\n",
    "‚Ä¢ Experience with deep learning frameworks (TensorFlow, PyTorch)\n",
    "‚Ä¢ Cloud platform experience (AWS, Azure, GCP)\n",
    "‚Ä¢ Knowledge of clinical data standards (HL7, FHIR)\n",
    "‚Ä¢ Experience with A/B testing and experimental design\n",
    "‚Ä¢ Publication record in data science or healthcare\n",
    "\n",
    "Responsibilities:\n",
    "‚Ä¢ Analyze large healthcare datasets to extract insights\n",
    "‚Ä¢ Build predictive models for patient outcomes\n",
    "‚Ä¢ Collaborate with clinical teams to understand data requirements\n",
    "‚Ä¢ Develop automated reporting and monitoring systems\n",
    "‚Ä¢ Present findings to stakeholders and leadership\n",
    "\n",
    "This role offers the opportunity to make a meaningful impact on patient care through data-driven insights.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"üìù Job description created ({len(job_description)} characters)\")\n",
    "print(\"\\nüéØ Job Focus: Data Scientist - Healthcare Technology\")\n",
    "print(\"üí° Key requirements: Python, R, ML, Healthcare data, 3+ years experience\")\n",
    "\n",
    "# Today's date for resume submission\n",
    "submission_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"üìÖ Analysis date: {submission_date}\")\n",
    "\n",
    "print(\"\\n‚úÖ Job description ready for relevance scoring!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7f3efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîç STEP 5: ANALYZING A SINGLE RESUME IN DETAIL\n",
      "============================================================\n",
      "üìÑ Analyzing: 2023-08-28 - Wesley Ordonez Resume Wesley Ordonez 2023 (Data Analytics).pdf\n",
      "‚è≥ This may take 30-60 seconds for the AI analysis...\n",
      "‚è±Ô∏è  Processing completed in 36.01 seconds\n",
      "üìä Extracted 47 fields from the resume\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Analyze Your First Resume\n",
    "print(\"\\nüîç STEP 5: ANALYZING A SINGLE RESUME IN DETAIL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not resume_paths:\n",
    "    print(\"‚ùå No resumes available for analysis\")\n",
    "    print(\"üí° Please add resume files to your resume directory first\")\n",
    "else:\n",
    "    # Select the first resume for detailed analysis\n",
    "    test_resume = resume_paths[0]\n",
    "    resume_filename = os.path.basename(test_resume)\n",
    "    \n",
    "    print(f\"üìÑ Analyzing: {resume_filename}\")\n",
    "    print(\"‚è≥ This may take 30-60 seconds for the AI analysis...\")\n",
    "    \n",
    "    # Parse the resume\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = parse_single_resume(\n",
    "        client=client,\n",
    "        resume_path=test_resume,\n",
    "        date_of_resume_submission=submission_date,\n",
    "        job_description=job_description\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"‚è±Ô∏è  Processing completed in {processing_time:.2f} seconds\")\n",
    "    print(f\"üìä Extracted {len(result)} fields from the resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65dcb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üë§ STEP 6: BASIC CANDIDATE INFORMATION\n",
      "==================================================\n",
      "üìã PERSONAL DETAILS:\n",
      "   ‚Ä¢ Name: Wesley Ordo√±ez\n",
      "   ‚Ä¢ Email: wesordonez1@gmail.com\n",
      "   ‚Ä¢ Phone: \n",
      "   ‚Ä¢ Location: \n",
      "\n",
      "üõ†Ô∏è  SKILLS (14 found):\n",
      "    1. CSS\n",
      "    2. HTML\n",
      "    3. JavaScript\n",
      "    4. Python\n",
      "    5. SQL\n",
      "    6. R\n",
      "    7. Tableau\n",
      "    8. Microsoft Power BI\n",
      "    9. Microsoft Suite\n",
      "   10. Google Suite\n",
      "   ... and 4 more skills\n",
      "\n",
      "üéì EDUCATION (2 entries):\n",
      "   1. Bachelor of Science in Mechanical Engineering (concentration: Design Engineering)\n",
      "      üè´ Rose-Hulman Institute of Technology (Unknown year)\n",
      "   2. Data Science and Machine Learning, Google Data Analytics Professional Certificate\n",
      "      üè´ Online Coursework (Udemy/Google) (Unknown year)\n",
      "\n",
      "üíº WORK EXPERIENCE (3 positions):\n",
      "   1. Unknown position\n",
      "      üè¢ Puerto Rican Cultural Center | ‚è±Ô∏è  Unknown duration\n",
      "   2. Unknown position\n",
      "      üè¢ Versatech LLC | ‚è±Ô∏è  Unknown duration\n",
      "   3. Unknown position\n",
      "      üè¢ ZF Automotive Group | ‚è±Ô∏è  Unknown duration\n",
      "\n",
      "‚úÖ Basic information extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Understanding the Basic Information\n",
    "print(\"\\nüë§ STEP 6: BASIC CANDIDATE INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'result' in locals():\n",
    "    print(\"üìã PERSONAL DETAILS:\")\n",
    "    print(f\"   ‚Ä¢ Name: {result.get('name', 'Not found')}\")\n",
    "    print(f\"   ‚Ä¢ Email: {result.get('email', 'Not found')}\")\n",
    "    print(f\"   ‚Ä¢ Phone: {result.get('contact_number', 'Not found')}\")\n",
    "    print(f\"   ‚Ä¢ Location: {result.get('location', 'Not specified')}\")\n",
    "    \n",
    "    # Skills\n",
    "    skills = result.get('skills', [])\n",
    "    if skills:\n",
    "        print(f\"\\nüõ†Ô∏è  SKILLS ({len(skills)} found):\")\n",
    "        # Show first 10 skills\n",
    "        for i, skill in enumerate(skills[:10], 1):\n",
    "            print(f\"   {i:2d}. {skill}\")\n",
    "        if len(skills) > 10:\n",
    "            print(f\"   ... and {len(skills) - 10} more skills\")\n",
    "    \n",
    "    # Education\n",
    "    educations = result.get('educations', [])\n",
    "    if educations:\n",
    "        print(f\"\\nüéì EDUCATION ({len(educations)} entries):\")\n",
    "        for i, edu in enumerate(educations, 1):\n",
    "            degree = edu.get('degree', 'Unknown degree')\n",
    "            institution = edu.get('institution', 'Unknown institution')\n",
    "            year = edu.get('graduation_year', 'Unknown year')\n",
    "            print(f\"   {i}. {degree}\")\n",
    "            print(f\"      üè´ {institution} ({year})\")\n",
    "    \n",
    "    # Work Experience\n",
    "    work_experiences = result.get('work_experiences', [])\n",
    "    if work_experiences:\n",
    "        print(f\"\\nüíº WORK EXPERIENCE ({len(work_experiences)} positions):\")\n",
    "        for i, work in enumerate(work_experiences[:5], 1):  # Show first 5\n",
    "            title = work.get('title', work.get('position', 'Unknown position'))\n",
    "            company = work.get('company', 'Unknown company')\n",
    "            duration = work.get('duration', 'Unknown duration')\n",
    "            print(f\"   {i}. {title}\")\n",
    "            print(f\"      üè¢ {company} | ‚è±Ô∏è  {duration}\")\n",
    "        if len(work_experiences) > 5:\n",
    "            print(f\"   ... and {len(work_experiences) - 5} more positions\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Basic information extracted successfully!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No resume analysis available. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f33280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üî¨ STEP 7: EXPLORING THE 21 UNIFIED EXTRACTOR FIELDS\n",
      "=================================================================\n",
      "üìä The unified extractor provides 21 specialized analysis fields:\n",
      "   This replaces multiple separate API calls with one comprehensive analysis\n",
      "\n",
      "üìà EXPERIENCE ANALYSIS:\n",
      "   ‚Ä¢ Total work experience (years): 5.8\n",
      "   ‚Ä¢ Relevant work experience (years): 3.7\n",
      "   ‚Ä¢ Education experience (years): 4.0\n",
      "   ‚Ä¢ Relevant education (years): 4.0\n",
      "   ‚Ä¢ Total relevant experience (years): 7.7\n",
      "   ‚Ä¢ Average company tenure (years): 1.9\n",
      "\n",
      "üéì EDUCATION ANALYSIS:\n",
      "   ‚Ä¢ Highest degree attained: Bachelor of Science\n",
      "   ‚Ä¢ Major/field of study: Mechanical Engineering\n",
      "   ‚Ä¢ Degree status (completed/in-progress): completed\n",
      "   ‚Ä¢ School prestige level: medium\n",
      "\n",
      "üíº CAREER ANALYSIS:\n",
      "   ‚Ä¢ Career seniority level: manager\n",
      "   ‚Ä¢ Primary job title/role: SBDC Business Advisor and Corridor Manager\n",
      "\n",
      "üìû PROFESSIONAL PROFILES:\n",
      "   ‚Ä¢ LinkedIn profile URL: Not available\n",
      "   ‚Ä¢ GitHub profile URL: Not available\n",
      "   ‚Ä¢ Personal website URL: Not available\n",
      "\n",
      "üéØ RELEVANCE SCORING EXPLANATION:\n",
      "   ‚Ä¢ Work relevance: 63.8% (3.7/5.8 years)\n",
      "   üü° Good match with some transferable skills\n",
      "\n",
      "‚úÖ All 21 fields analyzed in a single AI call!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Understanding the Unified Extractor Fields\n",
    "print(\"\\nüî¨ STEP 7: EXPLORING THE 21 UNIFIED EXTRACTOR FIELDS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if 'result' in locals():\n",
    "    print(\"üìä The unified extractor provides 21 specialized analysis fields:\")\n",
    "    print(\"   This replaces multiple separate API calls with one comprehensive analysis\")\n",
    "    \n",
    "    # Group fields by category for better understanding\n",
    "    experience_fields = {\n",
    "        'wyoe': 'Total work experience (years)',\n",
    "        'relevant_wyoe': 'Relevant work experience (years)',\n",
    "        'eyoe': 'Education experience (years)',\n",
    "        'relevant_eyoe': 'Relevant education (years)',\n",
    "        'total_relevant_yoe': 'Total relevant experience (years)',\n",
    "        'average_tenure_at_company_years': 'Average company tenure (years)'\n",
    "    }\n",
    "    \n",
    "    education_fields = {\n",
    "        'highest_degree': 'Highest degree attained',\n",
    "        'highest_degree_major': 'Major/field of study',\n",
    "        'highest_degree_status': 'Degree status (completed/in-progress)',\n",
    "        'highest_degree_school_prestige': 'School prestige level'\n",
    "    }\n",
    "    \n",
    "    career_fields = {\n",
    "        'highest_seniority_level': 'Career seniority level',\n",
    "        'primary_position_title': 'Primary job title/role'\n",
    "    }\n",
    "    \n",
    "    contact_fields = {\n",
    "        'linkedin_url': 'LinkedIn profile URL',\n",
    "        'github_url': 'GitHub profile URL',\n",
    "        'personal_website_url': 'Personal website URL'\n",
    "    }\n",
    "    \n",
    "    # Display experience analysis\n",
    "    print(f\"\\nüìà EXPERIENCE ANALYSIS:\")\n",
    "    for field, description in experience_fields.items():\n",
    "        value = result.get(field, 'Not calculated')\n",
    "        print(f\"   ‚Ä¢ {description}: {value}\")\n",
    "    \n",
    "    # Display education analysis\n",
    "    print(f\"\\nüéì EDUCATION ANALYSIS:\")\n",
    "    for field, description in education_fields.items():\n",
    "        value = result.get(field, 'Not found')\n",
    "        print(f\"   ‚Ä¢ {description}: {value}\")\n",
    "    \n",
    "    # Display career analysis\n",
    "    print(f\"\\nüíº CAREER ANALYSIS:\")\n",
    "    for field, description in career_fields.items():\n",
    "        value = result.get(field, 'Not determined')\n",
    "        print(f\"   ‚Ä¢ {description}: {value}\")\n",
    "    \n",
    "    # Display contact information\n",
    "    print(f\"\\nüìû PROFESSIONAL PROFILES:\")\n",
    "    for field, description in contact_fields.items():\n",
    "        value = result.get(field, 'Not found')\n",
    "        if value and value != 'Not found':\n",
    "            print(f\"   ‚Ä¢ {description}: {value}\")\n",
    "        else:\n",
    "            print(f\"   ‚Ä¢ {description}: Not available\")\n",
    "    \n",
    "    # Relevance calculation explanation\n",
    "    print(f\"\\nüéØ RELEVANCE SCORING EXPLANATION:\")\n",
    "    total_work = result.get('wyoe', 0)\n",
    "    relevant_work = result.get('relevant_wyoe', 0)\n",
    "    if total_work > 0:\n",
    "        relevance_percentage = (relevant_work / total_work) * 100\n",
    "        print(f\"   ‚Ä¢ Work relevance: {relevance_percentage:.1f}% ({relevant_work:.1f}/{total_work:.1f} years)\")\n",
    "        \n",
    "        if relevance_percentage >= 80:\n",
    "            print(\"   üü¢ Excellent match for this role!\")\n",
    "        elif relevance_percentage >= 60:\n",
    "            print(\"   üü° Good match with some transferable skills\")\n",
    "        elif relevance_percentage >= 40:\n",
    "            print(\"   üü† Moderate match, may need additional training\")\n",
    "        else:\n",
    "            print(\"   üî¥ Limited relevant experience for this specific role\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ All 21 fields analyzed in a single AI call!\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No analysis results available. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b717564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìö STEP 8: PROCESSING MULTIPLE RESUMES SYSTEMATICALLY\n",
      "=================================================================\n",
      "üìä Processing 5 resumes for comprehensive analysis\n",
      "‚è≥ This will take a few minutes - each resume requires AI analysis\n",
      "üîÑ We're using sequential processing for clear step-by-step learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing resumes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [02:11<00:00, 26.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Batch processing completed!\n",
      "‚è±Ô∏è  Total time: 131.28 seconds\n",
      "üìä Average per resume: 26.26 seconds\n",
      "üìã Results dataframe shape: (5, 55)\n",
      "üìà Columns available: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Batch Processing Multiple Resumes (Sequential)\n",
    "print(\"\\nüìö STEP 8: PROCESSING MULTIPLE RESUMES SYSTEMATICALLY\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if len(resume_paths) > 1:\n",
    "    # For tutorial purposes, we'll process a small batch sequentially\n",
    "    # This helps you understand each step without overwhelming output\n",
    "    \n",
    "    batch_size = min(5, len(resume_paths))  # Process up to 5 resumes\n",
    "    batch_resumes = resume_paths[:batch_size]\n",
    "    \n",
    "    print(f\"üìä Processing {batch_size} resumes for comprehensive analysis\")\n",
    "    print(\"‚è≥ This will take a few minutes - each resume requires AI analysis\")\n",
    "    print(\"üîÑ We're using sequential processing for clear step-by-step learning\")\n",
    "    \n",
    "    # Process resumes one by one (sequential, not parallel)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df = parse_many_resumes(\n",
    "        client=client,\n",
    "        resume_paths=batch_resumes,\n",
    "        date_of_resume_submission=submission_date,\n",
    "        job_description=job_description,\n",
    "        parallel=False,  # Sequential processing for learning\n",
    "        use_tqdm=True   # Show progress bar\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n‚úÖ Batch processing completed!\")\n",
    "    print(f\"‚è±Ô∏è  Total time: {processing_time:.2f} seconds\")\n",
    "    print(f\"üìä Average per resume: {processing_time/batch_size:.2f} seconds\")\n",
    "    print(f\"üìã Results dataframe shape: {df.shape}\")\n",
    "    print(f\"üìà Columns available: {len(df.columns)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ÑπÔ∏è  Only one resume available. Add more resumes to try batch processing.\")\n",
    "    # Create a single-row dataframe for consistency\n",
    "    if 'result' in locals():\n",
    "        df = pd.DataFrame([result])\n",
    "        df['parsing_status'] = 'success'\n",
    "        df['filename'] = os.path.basename(test_resume)\n",
    "        print(\"üìä Single resume converted to dataframe format for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd14120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä STEP 9: UNDERSTANDING BATCH ANALYSIS RESULTS\n",
      "============================================================\n",
      "üìà PROCESSING SUMMARY:\n",
      "   ‚Ä¢ Total resumes processed: 5\n",
      "   ‚Ä¢ Successfully analyzed: 5\n",
      "   ‚Ä¢ Failed to process: 0\n",
      "   ‚Ä¢ Success rate: 100.0%\n",
      "\n",
      "üìä EXPERIENCE STATISTICS:\n",
      "   ‚Ä¢ Average total work experience: 8.2 years\n",
      "   ‚Ä¢ Average relevant work experience: 3.5 years\n",
      "   ‚Ä¢ Average education experience: 5.0 years\n",
      "   ‚Ä¢ Overall relevance ratio: 42.1%\n",
      "\n",
      "üéì EDUCATION DISTRIBUTION:\n",
      "   ‚Ä¢ Bachelor of Science: 2 candidates (40.0%)\n",
      "   ‚Ä¢ Master of Science: 2 candidates (40.0%)\n",
      "\n",
      "üíº SENIORITY LEVEL DISTRIBUTION:\n",
      "   ‚Ä¢ mid-level: 3 candidates (60.0%)\n",
      "   ‚Ä¢ manager: 1 candidates (20.0%)\n",
      "   ‚Ä¢ executive: 1 candidates (20.0%)\n",
      "\n",
      "üìû CONTACT INFORMATION AVAILABILITY:\n",
      "   ‚Ä¢ Email addresses: 5/5 (100.0%)\n",
      "   ‚Ä¢ LinkedIn profiles: 2/5 (40.0%)\n",
      "   ‚Ä¢ GitHub profiles: 3/5 (60.0%)\n",
      "\n",
      "üèÜ TOP 3 CANDIDATES BY RELEVANCE:\n",
      "   1. Akhil Bukkapuram\n",
      "      üéØ Relevance: 74.2% | üíº Experience: 3.1 years | üéì Master of Science\n",
      "   2. Wesley Ordo√±ez\n",
      "      üéØ Relevance: 57.6% | üíº Experience: 5.9 years | üéì Bachelor of Science\n",
      "   3. Stefani Sanchez\n",
      "      üéØ Relevance: 44.1% | üíº Experience: 6.8 years | üéì Bachelor of Science\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Analyzing Batch Results\n",
    "print(\"\\nüìä STEP 9: UNDERSTANDING BATCH ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Check processing success\n",
    "    total_resumes = len(df)\n",
    "    successful = len(df[df['parsing_status'] == 'success'])\n",
    "    failed = len(df[df['parsing_status'] == 'failed'])\n",
    "    \n",
    "    print(f\"üìà PROCESSING SUMMARY:\")\n",
    "    print(f\"   ‚Ä¢ Total resumes processed: {total_resumes}\")\n",
    "    print(f\"   ‚Ä¢ Successfully analyzed: {successful}\")\n",
    "    print(f\"   ‚Ä¢ Failed to process: {failed}\")\n",
    "    print(f\"   ‚Ä¢ Success rate: {successful/total_resumes*100:.1f}%\")\n",
    "    \n",
    "    if successful > 0:\n",
    "        successful_df = df[df['parsing_status'] == 'success']\n",
    "        \n",
    "        # Experience statistics\n",
    "        print(f\"\\nüìä EXPERIENCE STATISTICS:\")\n",
    "        avg_total_exp = successful_df['wyoe'].mean()\n",
    "        avg_relevant_exp = successful_df['relevant_wyoe'].mean()\n",
    "        avg_education_exp = successful_df['eyoe'].mean()\n",
    "        \n",
    "        print(f\"   ‚Ä¢ Average total work experience: {avg_total_exp:.1f} years\")\n",
    "        print(f\"   ‚Ä¢ Average relevant work experience: {avg_relevant_exp:.1f} years\")\n",
    "        print(f\"   ‚Ä¢ Average education experience: {avg_education_exp:.1f} years\")\n",
    "        print(f\"   ‚Ä¢ Overall relevance ratio: {avg_relevant_exp/avg_total_exp*100:.1f}%\")\n",
    "        \n",
    "        # Education distribution\n",
    "        print(f\"\\nüéì EDUCATION DISTRIBUTION:\")\n",
    "        education_counts = successful_df['highest_degree'].value_counts()\n",
    "        for degree, count in education_counts.items():\n",
    "            percentage = count / len(successful_df) * 100\n",
    "            print(f\"   ‚Ä¢ {degree}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Seniority distribution\n",
    "        print(f\"\\nüíº SENIORITY LEVEL DISTRIBUTION:\")\n",
    "        seniority_counts = successful_df['highest_seniority_level'].value_counts()\n",
    "        for level, count in seniority_counts.items():\n",
    "            percentage = count / len(successful_df) * 100\n",
    "            print(f\"   ‚Ä¢ {level}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Contact information availability\n",
    "        linkedin_available = successful_df['linkedin_url'].notna().sum()\n",
    "        github_available = successful_df['github_url'].notna().sum()\n",
    "        email_available = successful_df['email'].notna().sum()\n",
    "        \n",
    "        print(f\"\\nüìû CONTACT INFORMATION AVAILABILITY:\")\n",
    "        print(f\"   ‚Ä¢ Email addresses: {email_available}/{successful} ({email_available/successful*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ LinkedIn profiles: {linkedin_available}/{successful} ({linkedin_available/successful*100:.1f}%)\")\n",
    "        print(f\"   ‚Ä¢ GitHub profiles: {github_available}/{successful} ({github_available/successful*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate relevance rankings\n",
    "        successful_df['relevance_percentage'] = (\n",
    "            successful_df['relevant_wyoe'] / successful_df['wyoe'] * 100\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # Show top candidates\n",
    "        top_candidates = successful_df.nlargest(3, 'relevance_percentage')\n",
    "        print(f\"\\nüèÜ TOP 3 CANDIDATES BY RELEVANCE:\")\n",
    "        for idx, (_, candidate) in enumerate(top_candidates.iterrows(), 1):\n",
    "            name = candidate.get('name', 'Unknown')\n",
    "            relevance = candidate.get('relevance_percentage', 0)\n",
    "            total_exp = candidate.get('wyoe', 0)\n",
    "            degree = candidate.get('highest_degree', 'Unknown')\n",
    "            print(f\"   {idx}. {name}\")\n",
    "            print(f\"      üéØ Relevance: {relevance:.1f}% | üíº Experience: {total_exp:.1f} years | üéì {degree}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"‚ùå No successful analyses to display\")\n",
    "        print(\"üí° Check your resume files and job description\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No batch processing results available. Run Step 8 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üíæ STEP 10: EXPORTING RESULTS FOR YOUR APPLICATIONS\n",
      "=================================================================\n",
      "üìä Complete results exported: tutorial_results/complete_analysis_20250529_205836.csv\n",
      "üéØ Candidate summary exported: tutorial_results/candidate_summary_20250529_205836.csv\n",
      "üîó JSON format exported: tutorial_results/candidates_20250529_205836.json\n",
      "\n",
      "üìÅ All files saved to: /Users/samcelarek/Documents/CVInsight/examples/tutorial_results\n",
      "\n",
      "üîó INTEGRATION EXAMPLES:\n",
      "==============================\n",
      "üìä Loading results in your application:\n",
      "\n",
      "import pandas as pd\n",
      "import json\n",
      "\n",
      "# Load CSV results\n",
      "df = pd.read_csv('tutorial_results/candidate_summary_*.csv')\n",
      "\n",
      "# Load JSON results\n",
      "with open('tutorial_results/candidates_*.json', 'r') as f:\n",
      "    candidates = json.load(f)\n",
      "\n",
      "# Filter high-relevance candidates (70%+ relevant experience)\n",
      "top_candidates = df[df['relevance_percentage'] >= 70]\n",
      "\n",
      "# Extract contact information\n",
      "contacts = top_candidates[['name', 'email', 'linkedin_url']].dropna()\n",
      "\n",
      "üîÑ Using in a recruitment pipeline:\n",
      "\n",
      "# Example integration with your HR system\n",
      "for _, candidate in top_candidates.iterrows():\n",
      "    candidate_profile = {\n",
      "        'name': candidate['name'],\n",
      "        'email': candidate['email'],\n",
      "        'relevance_score': candidate['relevance_percentage'],\n",
      "        'experience_years': candidate['all_wyoe'],\n",
      "        'education': candidate['highest_degree'],\n",
      "        'seniority': candidate['highest_seniority_level']\n",
      "    }\n",
      "\n",
      "    # Add to your database or send to your API\n",
      "    add_candidate_to_system(candidate_profile)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Export Results for Integration\n",
    "print(\"\\nüíæ STEP 10: EXPORTING RESULTS FOR YOUR APPLICATIONS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if 'df' in locals() and len(df) > 0:\n",
    "    # Create results directory\n",
    "    results_dir = Path(\"./tutorial_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Export complete results\n",
    "    complete_file = results_dir / f\"complete_analysis_{timestamp}.csv\"\n",
    "    df.to_csv(complete_file, index=False)\n",
    "    print(f\"üìä Complete results exported: {complete_file}\")\n",
    "    \n",
    "    # Export successful results only\n",
    "    successful_df = df[df['parsing_status'] == 'success']\n",
    "    if not successful_df.empty:\n",
    "        # Create a summary with key fields\n",
    "        summary_fields = [\n",
    "            'filename', 'name', 'email', 'contact_number',\n",
    "            'wyoe', 'relevant_wyoe', 'eyoe',\n",
    "            'highest_degree', 'highest_seniority_level', 'primary_position_title',\n",
    "            'linkedin_url', 'github_url'\n",
    "        ]\n",
    "        \n",
    "        # Only include fields that exist in the dataframe\n",
    "        available_fields = [field for field in summary_fields if field in successful_df.columns]\n",
    "        summary_df = successful_df[available_fields].copy()\n",
    "        \n",
    "        # Add calculated relevance percentage\n",
    "        summary_df['relevance_percentage'] = (\n",
    "            successful_df['relevant_wyoe'] / successful_df['wyoe'] * 100\n",
    "        ).fillna(0).round(1)\n",
    "        \n",
    "        # Sort by relevance\n",
    "        summary_df = summary_df.sort_values('relevance_percentage', ascending=False)\n",
    "        \n",
    "        summary_file = results_dir / f\"candidate_summary_{timestamp}.csv\"\n",
    "        summary_df.to_csv(summary_file, index=False)\n",
    "        print(f\"üéØ Candidate summary exported: {summary_file}\")\n",
    "        \n",
    "        # Create a JSON export for easy API integration\n",
    "        json_file = results_dir / f\"candidates_{timestamp}.json\"\n",
    "        candidates_json = summary_df.to_dict('records')\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(candidates_json, f, indent=2)\n",
    "        print(f\"üîó JSON format exported: {json_file}\")\n",
    "    \n",
    "    print(f\"\\nüìÅ All files saved to: {results_dir.absolute()}\")\n",
    "    \n",
    "    # Show integration examples\n",
    "    print(f\"\\nüîó INTEGRATION EXAMPLES:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"üìä Loading results in your application:\")\n",
    "    print(\"\"\"\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV results\n",
    "df = pd.read_csv('tutorial_results/candidate_summary_*.csv')\n",
    "\n",
    "# Load JSON results\n",
    "with open('tutorial_results/candidates_*.json', 'r') as f:\n",
    "    candidates = json.load(f)\n",
    "\n",
    "# Filter high-relevance candidates (70%+ relevant experience)\n",
    "top_candidates = df[df['relevance_percentage'] >= 70]\n",
    "\n",
    "# Extract contact information\n",
    "contacts = top_candidates[['name', 'email', 'linkedin_url']].dropna()\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"üîÑ Using in a recruitment pipeline:\")\n",
    "    print(\"\"\"\n",
    "# Example integration with your HR system\n",
    "for _, candidate in top_candidates.iterrows():\n",
    "    candidate_profile = {\n",
    "        'name': candidate['name'],\n",
    "        'email': candidate['email'],\n",
    "        'relevance_score': candidate['relevance_percentage'],\n",
    "        'experience_years': candidate['wyoe'],\n",
    "        'education': candidate['highest_degree'],\n",
    "        'seniority': candidate['highest_seniority_level']\n",
    "    }\n",
    "    \n",
    "    # Add to your database or send to your API\n",
    "    add_candidate_to_system(candidate_profile)\n",
    "\"\"\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ùå No results to export. Complete the analysis steps first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16dd69",
   "metadata": {},
   "source": [
    "## üéâ Tutorial Complete!\n",
    "\n",
    "### ‚úÖ **What You've Learned:**\n",
    "\n",
    "1. **Setup & Configuration**: How to integrate CVInsight into any Python project\n",
    "2. **Client Initialization**: Setting up the AI-powered analysis engine\n",
    "3. **Single Resume Analysis**: Deep dive into one candidate's profile\n",
    "4. **Unified Extractor**: Understanding all 21 analysis fields\n",
    "5. **Job Relevance Scoring**: How job descriptions affect candidate rankings\n",
    "6. **Batch Processing**: Systematically analyzing multiple resumes\n",
    "7. **Results Interpretation**: Making sense of the analysis data\n",
    "8. **Data Export**: Preparing results for integration into your applications\n",
    "\n",
    "### üöÄ **Key Takeaways:**\n",
    "\n",
    "- **Unified Extractor**: Gets 21 analysis fields in one AI call (75% faster!)\n",
    "- **Job-Specific Relevance**: Candidates are scored against your specific requirements\n",
    "- **Comprehensive Profiling**: Experience, education, skills, seniority, and contact info\n",
    "- **Easy Integration**: Export to CSV, JSON, or direct API integration\n",
    "- **Production Ready**: Handle both single resumes and large batches\n",
    "\n",
    "### üìä **Understanding the 21 Fields:**\n",
    "\n",
    "**Experience Fields:**\n",
    "- `wyoe`: Total work experience years\n",
    "- `relevant_wyoe`: Work experience relevant to the job\n",
    "- `eyoe`: Education experience years\n",
    "- `relevant_eyoe`: Education relevant to the job\n",
    "- `total_relevant_yoe`: Combined relevant experience\n",
    "- `average_tenure_at_company_years`: Job stability indicator\n",
    "\n",
    "**Education Fields:**\n",
    "- `highest_degree`: Bachelor's, Master's, PhD, etc.\n",
    "- `highest_degree_major`: Field of study\n",
    "- `highest_degree_status`: Completed or in-progress\n",
    "- `highest_degree_school_prestige`: School ranking\n",
    "\n",
    "**Career Fields:**\n",
    "- `highest_seniority_level`: Junior, Mid, Senior, Executive\n",
    "- `primary_position_title`: Main job role\n",
    "\n",
    "**Contact Fields:**\n",
    "- `linkedin_url`, `github_url`, `personal_website_url`: Professional profiles\n",
    "\n",
    "### üí° **Next Steps:**\n",
    "\n",
    "1. **Try Different Job Descriptions**: See how relevance scores change\n",
    "2. **Process Your Own Resumes**: Upload your actual candidate files\n",
    "3. **Integrate with Your Systems**: Use the exported data in your applications\n",
    "4. **Explore Concurrent Processing**: Try the concurrent analysis demo for speed\n",
    "5. **Production Deployment**: Use the production batch processor for scale\n",
    "\n",
    "### üîó **Integration Checklist:**\n",
    "\n",
    "- [ ] Clone CVInsight to your projects directory\n",
    "- [ ] Install dependencies (`pip install -r requirements.txt`)\n",
    "- [ ] Set up your OpenAI API key\n",
    "- [ ] Test with a few sample resumes\n",
    "- [ ] Customize job descriptions for your roles\n",
    "- [ ] Set up automated exports to your systems\n",
    "- [ ] Implement candidate ranking in your workflow\n",
    "\n",
    "**You're now ready to build powerful resume analysis applications with CVInsight!** üéØ\n",
    "\n",
    "---\n",
    "\n",
    "*This tutorial used sequential processing for educational clarity. For production applications with many resumes, consider using the concurrent processing capabilities shown in our other examples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fafd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "üéØ BONUS: LLM PREDICTION VALIDATION\n",
      "============================================================\n",
      "Let's validate our LLM predictions against known truth values!\n",
      "\n",
      "üìä Loaded truth values for 19 candidates\n",
      "\n",
      "Sample of truth data:\n",
      "               name  LLM Estimated YoE  TYOE  Work Exp Years  Edu Years\n",
      "0         AKASH DAS               4.00   2.5               0        2.5\n",
      "1  Akhil Bukkapuram               4.92   4.5               2        2.5\n",
      "2     AndrewColbert               7.42   7.0               4        3.0\n",
      "3      Brian Warras              10.33   3.1               3        0.1\n",
      "4     Bryan Aguilar               5.42   9.0               6        3.0\n",
      "\n",
      "‚ö†Ô∏è No batch processing results available for validation.\n",
      "Run the batch processing steps above first to generate results for validation.\n",
      "\n",
      "To see validation in action, process some of the resumes that match the truth dataset:\n",
      "Available candidates in truth data:\n",
      "  - AKASH DAS\n",
      "  - Akhil Bukkapuram\n",
      "  - AndrewColbert\n",
      "  - Brian Warras\n",
      "  - Bryan Aguilar\n",
      "  - Doris Fang\n",
      "  - ELIANA MUGAR\n",
      "  - Eric de la Parra\n",
      "  - HARRISON JAMES WEEKS\n",
      "  - John Gianatasio, II.\n"
     ]
    }
   ],
   "source": [
    "# BONUS: LLM Prediction Validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"üéØ BONUS: LLM PREDICTION VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"Let's validate our LLM predictions against known truth values!\")\n",
    "\n",
    "# Load truth values from CSV\n",
    "truth_df = pd.read_csv('/Users/samcelarek/Documents/CVInsight/examples/yoe_truth_values.csv')\n",
    "print(f\"\\nüìä Loaded truth values for {len(truth_df)} candidates\")\n",
    "print(\"\\nSample of truth data:\")\n",
    "print(truth_df[['name', 'LLM Estimated YoE', 'TYOE', 'Work Exp Years', 'Edu Years']].head())\n",
    "\n",
    "# Normalize names for matching (remove spaces, convert to lowercase)\n",
    "def normalize_name(name):\n",
    "    return str(name).replace(' ', '').replace(',', '').replace('.', '').lower().strip()\n",
    "\n",
    "truth_df['normalized_name'] = truth_df['name'].apply(normalize_name)\n",
    "\n",
    "# Check if we have results to validate\n",
    "if 'batch_results' in locals() and batch_results is not None:\n",
    "    print(\"\\nüîç Validating our tutorial results against actual values...\")\n",
    "    \n",
    "    # Create validation DataFrame\n",
    "    validation_results = []\n",
    "    \n",
    "    for _, candidate in batch_results.iterrows():\n",
    "        if candidate['parsing_status'] == 'success':\n",
    "            candidate_normalized = normalize_name(candidate.get('name', ''))\n",
    "            \n",
    "            # Find matching truth value\n",
    "            truth_match = truth_df[truth_df['normalized_name'] == candidate_normalized]\n",
    "            \n",
    "            if not truth_match.empty:\n",
    "                truth_row = truth_match.iloc[0]\n",
    "                \n",
    "                print(f\"\\nüîç Validating: {candidate['name']}\")\n",
    "                \n",
    "                # Extract LLM predictions from our processing\n",
    "                llm_work_exp = candidate.get('work_experience_years', 0)\n",
    "                llm_edu_years = candidate.get('education_years', 0)\n",
    "                llm_total_yoe = llm_work_exp + llm_edu_years  # Calculate LLM total from components\n",
    "                \n",
    "                # Extract truth values\n",
    "                actual_work_exp = truth_row['Work Exp Years']\n",
    "                actual_edu_years = truth_row['Edu Years']\n",
    "                actual_total_yoe = truth_row['TYOE']\n",
    "                \n",
    "                # Calculate errors (comparing LLM predictions vs truth values)\n",
    "                work_exp_error = abs(llm_work_exp - actual_work_exp)\n",
    "                edu_years_error = abs(llm_edu_years - actual_edu_years)\n",
    "                total_yoe_error = abs(llm_total_yoe - actual_total_yoe)\n",
    "                \n",
    "                print(f\"  Work Experience: LLM={llm_work_exp}, Actual={actual_work_exp}, Error={work_exp_error:.1f}\")\n",
    "                print(f\"  Education Years: LLM={llm_edu_years}, Actual={actual_edu_years}, Error={edu_years_error:.1f}\")\n",
    "                print(f\"  Total YoE: LLM Calc.={llm_total_yoe}, Actual={actual_total_yoe}, Error={total_yoe_error:.1f}\")\n",
    "                \n",
    "                validation_results.append({\n",
    "                    'name': candidate['name'],\n",
    "                    'llm_work_exp': llm_work_exp,\n",
    "                    'actual_work_exp': actual_work_exp,\n",
    "                    'work_exp_error': work_exp_error,\n",
    "                    'llm_edu_years': llm_edu_years,\n",
    "                    'actual_edu_years': actual_edu_years,\n",
    "                    'edu_years_error': edu_years_error,\n",
    "                    'llm_total_yoe': llm_total_yoe,\n",
    "                    'actual_total_yoe': actual_total_yoe,\n",
    "                    'total_yoe_error': total_yoe_error\n",
    "                })\n",
    "    \n",
    "    if validation_results:\n",
    "        validation_df = pd.DataFrame(validation_results)\n",
    "        \n",
    "        print(f\"\\n\\n‚úÖ VALIDATION COMPLETE: Matched {len(validation_df)} candidates\")\n",
    "        print(\"\\nüìä VALIDATION SUMMARY:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mean_work_error = validation_df['work_exp_error'].mean()\n",
    "        mean_edu_error = validation_df['edu_years_error'].mean()\n",
    "        mean_yoe_error = validation_df['total_yoe_error'].mean()\n",
    "        \n",
    "        print(f\"Mean Work Experience Error: {mean_work_error:.2f} years\")\n",
    "        print(f\"Mean Education Years Error: {mean_edu_error:.2f} years\")\n",
    "        print(f\"Mean Total YoE Error: {mean_yoe_error:.2f} years\")\n",
    "        \n",
    "        # Accuracy assessment\n",
    "        work_within_1_year = len(validation_df[validation_df['work_exp_error'] <= 1]) / len(validation_df) * 100\n",
    "        edu_within_1_year = len(validation_df[validation_df['edu_years_error'] <= 1]) / len(validation_df) * 100\n",
    "        yoe_within_2_years = len(validation_df[validation_df['total_yoe_error'] <= 2]) / len(validation_df) * 100\n",
    "        \n",
    "        print(f\"\\nüéØ ACCURACY METRICS:\")\n",
    "        print(f\"Work Experience within 1 year: {work_within_1_year:.1f}%\")\n",
    "        print(f\"Education Years within 1 year: {edu_within_1_year:.1f}%\")\n",
    "        print(f\"Total YoE within 2 years: {yoe_within_2_years:.1f}%\")\n",
    "        \n",
    "        # Show best and worst predictions\n",
    "        print(\"\\n‚úÖ MOST ACCURATE PREDICTIONS:\")\n",
    "        best_predictions = validation_df.nsmallest(3, 'total_yoe_error')\n",
    "        for _, row in best_predictions.iterrows():\n",
    "            print(f\"  {row['name']}: Total YoE Error = {row['total_yoe_error']:.1f} years\")\n",
    "        \n",
    "        print(\"\\n‚ùå LEAST ACCURATE PREDICTIONS:\")\n",
    "        worst_predictions = validation_df.nlargest(3, 'total_yoe_error')\n",
    "        for _, row in worst_predictions.iterrows():\n",
    "            print(f\"  {row['name']}: Total YoE Error = {row['total_yoe_error']:.1f} years\")\n",
    "        \n",
    "        # Save validation results\n",
    "        output_path = './tutorial_results/tutorial_validation_results.csv'\n",
    "        validation_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\nüíæ Validation results saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\nüéÜ TUTORIAL COMPLETE!\")\n",
    "        print(\"You've learned how to:\")\n",
    "        print(\"‚úì Process resumes with CVInsight\")\n",
    "        print(\"‚úì Analyze and interpret results\")\n",
    "        print(\"‚úì Validate LLM predictions against truth values\")\n",
    "        print(\"‚úì Export data for integration\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No matching candidates found for validation\")\n",
    "        print(\"This might happen if the resumes processed don't match the truth dataset.\")\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è No batch processing results available for validation.\")\n",
    "    print(\"Run the batch processing steps above first to generate results for validation.\")\n",
    "    print(\"\\nTo see validation in action, process some of the resumes that match the truth dataset:\")\n",
    "    print(\"Available candidates in truth data:\")\n",
    "    for name in truth_df['name'].head(10):\n",
    "        print(f\"  - {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
