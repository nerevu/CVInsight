{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53a85aa9",
   "metadata": {},
   "source": [
    "# CVInsight Step-by-Step Tutorial\n",
    "\n",
    "Welcome to CVInsight! This comprehensive tutorial will walk you through resume analysis step-by-step, perfect for learning how the system works and understanding each component.\n",
    "\n",
    "## 🎯 **Learning Objectives**\n",
    "- Understand CVInsight's unified extractor architecture\n",
    "- Learn to analyze individual resumes in detail\n",
    "- Master job-specific relevance scoring\n",
    "- Process multiple resumes systematically\n",
    "- Export and interpret results\n",
    "\n",
    "## 👥 **Who This Is For**\n",
    "- New users learning CVInsight\n",
    "- Developers integrating resume analysis\n",
    "- HR professionals understanding candidate scoring\n",
    "- Students learning NLP and resume processing\n",
    "\n",
    "## 📚 **Tutorial Structure**\n",
    "1. **Setup & Initialization** - Get CVInsight running\n",
    "2. **Single Resume Analysis** - Deep dive into one resume\n",
    "3. **Understanding the Fields** - Explore all 21 analysis fields\n",
    "4. **Job Relevance Scoring** - How job descriptions affect results\n",
    "5. **Batch Processing** - Handle multiple resumes systematically\n",
    "6. **Results Interpretation** - Make sense of the data\n",
    "7. **Integration & Export** - Use results in your applications\n",
    "\n",
    "## 🔧 **External Repository Integration**\n",
    "```bash\n",
    "# Clone CVInsight to your projects directory\n",
    "git clone https://github.com/your-username/CVInsight.git\n",
    "\n",
    "# Install dependencies\n",
    "cd CVInsight\n",
    "pip install -r requirements.txt\n",
    "\n",
    "# Set up your OpenAI API key\n",
    "export OPEN_AI_API_KEY=\"your-key-here\"\n",
    "\n",
    "# Now you can use CVInsight from any notebook!\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1679f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 STEP 1: SETTING UP CVINSIGHT\n",
      "==================================================\n",
      "📁 CVInsight path: /Users/samcelarek/Documents/CVInsight\n",
      "✅ CVInsight successfully imported!\n",
      "📦 Available functions:\n",
      "   • initialize_client() - Set up the AI client\n",
      "   • find_resumes() - Discover resume files\n",
      "   • parse_single_resume() - Analyze one resume\n",
      "   • parse_many_resumes() - Batch process multiple resumes\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup and Imports\n",
    "print(\"🚀 STEP 1: SETTING UP CVINSIGHT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "# Add CVInsight to your Python path\n",
    "# Adjust this path to where you cloned CVInsight\n",
    "CVINSIGHT_PATH = \"/Users/samcelarek/Documents/CVInsight\"\n",
    "if CVINSIGHT_PATH not in sys.path:\n",
    "    sys.path.insert(0, CVINSIGHT_PATH)\n",
    "\n",
    "print(f\"📁 CVInsight path: {CVINSIGHT_PATH}\")\n",
    "\n",
    "# Import CVInsight functions\n",
    "try:\n",
    "    from cvinsight.notebook_utils import (\n",
    "        initialize_client,\n",
    "        find_resumes,\n",
    "        parse_single_resume,\n",
    "        parse_many_resumes\n",
    "    )\n",
    "    print(\"✅ CVInsight successfully imported!\")\n",
    "    print(\"📦 Available functions:\")\n",
    "    print(\"   • initialize_client() - Set up the AI client\")\n",
    "    print(\"   • find_resumes() - Discover resume files\")\n",
    "    print(\"   • parse_single_resume() - Analyze one resume\")\n",
    "    print(\"   • parse_many_resumes() - Batch process multiple resumes\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "    print(\"💡 Make sure CVInsight is cloned and the path is correct!\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a8ea860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔧 STEP 2: INITIALIZING THE AI CLIENT\n",
      "==================================================\n",
      "🔄 Initializing CVInsight client...\n",
      "📊 Found 6 extractors:\n",
      "   • profile_extractor\n",
      "   • skills_extractor\n",
      "   • education_extractor\n",
      "   • experience_extractor\n",
      "   • yoe_extractor\n",
      "   • extended_analysis_extractor\n",
      "\n",
      "✅ Unified extractor is ready!\n",
      "🚀 This extractor provides all 21 analysis fields in a single call\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Initialize the CVInsight Client\n",
    "print(\"\\n🔧 STEP 2: INITIALIZING THE AI CLIENT\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Get your OpenAI API key\n",
    "api_key = os.environ.get(\"OPEN_AI_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"🔑 API key not found in environment variables\")\n",
    "    print(\"💡 You can either:\")\n",
    "    print(\"   1. Set it as an environment variable: export OPEN_AI_API_KEY='your-key'\")\n",
    "    print(\"   2. Enter it manually below\")\n",
    "    api_key = input(\"Enter your OpenAI API key: \")\n",
    "\n",
    "print(\"🔄 Initializing CVInsight client...\")\n",
    "\n",
    "# Initialize the client\n",
    "client = initialize_client(api_key=api_key)\n",
    "\n",
    "# Check what extractors are available\n",
    "extractors = list(client._plugin_manager.extractors.keys())\n",
    "print(f\"📊 Found {len(extractors)} extractors:\")\n",
    "for extractor in extractors:\n",
    "    print(f\"   • {extractor}\")\n",
    "\n",
    "# Verify the unified extractor is available\n",
    "if 'extended_analysis_extractor' in extractors:\n",
    "    print(\"\\n✅ Unified extractor is ready!\")\n",
    "    print(\"🚀 This extractor provides all 21 analysis fields in a single call\")\n",
    "else:\n",
    "    print(\"\\n❌ Unified extractor not found!\")\n",
    "    print(\"💡 Make sure you have the latest CVInsight version\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9fda61c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📁 STEP 3: FINDING RESUME FILES\n",
      "========================================\n",
      "🔍 Searching for resumes in: /Users/samcelarek/Documents/CVInsight/Resumes\n",
      "📄 Found 21 resume files\n",
      "\n",
      "📋 Resume files discovered:\n",
      "    1. 2023-08-28 - Wesley Ordonez Resume Wesley Ordonez 2023 (Data Analytics).pdf (85.0 KB)\n",
      "    2. 2023-08-20 - Weihao Chen Resume Resume_Weihao Chen.pdf (95.4 KB)\n",
      "    3. 2023-08-26 - Akhil Bukkapuram Resume Akhil_ds.pdf (200.7 KB)\n",
      "    4. 2023-08-28 - Brian Warras Resume BrianWarras.pdf (236.5 KB)\n",
      "    5. 2023-08-22 - Stefani Sanchez Resume Stefani Sanchez Resume.pdf (61.6 KB)\n",
      "    6. Gaurav_Kumar.pdf (309.0 KB)\n",
      "    7. 2023-08-25 - Ka Yee Yuen Resume Resume_Claire-Yuen.pdf (91.9 KB)\n",
      "    8. 2023-08-16 - Niveditha Channapatna Raju Resume nivedithacr_resume.pdf (74.2 KB)\n",
      "    9. 2023-08-20 - Bryan Aguilar Resume Bryan's Resume.pdf (80.5 KB)\n",
      "   10. 2023-08-23 - Eliana Mugar Resume Eliana Mugar_NLPCS.pdf (94.6 KB)\n",
      "   ... and 11 more files\n",
      "\n",
      "📊 Supported formats: PDF, DOC, DOCX\n",
      "💡 CVInsight will extract text from all these formats automatically\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Discover Resume Files\n",
    "print(\"\\n📁 STEP 3: FINDING RESUME FILES\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Set your resume directory path\n",
    "# Adjust this to where your resume files are located\n",
    "resume_dir = \"/Users/samcelarek/Documents/CVInsight/Resumes\"  # Change this path!\n",
    "\n",
    "print(f\"🔍 Searching for resumes in: {resume_dir}\")\n",
    "\n",
    "# Find all resume files\n",
    "resume_paths = find_resumes(resume_dir)\n",
    "\n",
    "print(f\"📄 Found {len(resume_paths)} resume files\")\n",
    "\n",
    "if resume_paths:\n",
    "    print(\"\\n📋 Resume files discovered:\")\n",
    "    for i, path in enumerate(resume_paths[:10], 1):  # Show first 10\n",
    "        filename = os.path.basename(path)\n",
    "        file_size = os.path.getsize(path) / 1024  # Size in KB\n",
    "        print(f\"   {i:2d}. {filename} ({file_size:.1f} KB)\")\n",
    "    \n",
    "    if len(resume_paths) > 10:\n",
    "        print(f\"   ... and {len(resume_paths) - 10} more files\")\n",
    "    \n",
    "    print(f\"\\n📊 Supported formats: PDF, DOC, DOCX\")\n",
    "    print(f\"💡 CVInsight will extract text from all these formats automatically\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No resume files found!\")\n",
    "    print(\"💡 Make sure to:\")\n",
    "    print(\"   • Check the resume_dir path is correct\")\n",
    "    print(\"   • Add some PDF, DOC, or DOCX resume files\")\n",
    "    print(\"   • Ensure the files are readable\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8d6dc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 STEP 4: DEFINING THE JOB DESCRIPTION\n",
      "==================================================\n",
      "📝 Job description created (1388 characters)\n",
      "\n",
      "🎯 Job Focus: Data Scientist - Healthcare Technology\n",
      "💡 Key requirements: Python, R, ML, Healthcare data, 3+ years experience\n",
      "📅 Analysis date: 2025-05-29\n",
      "\n",
      "✅ Job description ready for relevance scoring!\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Create a Job Description\n",
    "print(\"\\n📋 STEP 4: DEFINING THE JOB DESCRIPTION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Create a detailed job description\n",
    "# This will be used to calculate relevance scores\n",
    "job_description = \"\"\"\n",
    "Data Scientist Position - Healthcare Technology\n",
    "\n",
    "We are seeking a talented Data Scientist to join our healthcare technology team. The ideal candidate will have:\n",
    "\n",
    "Required Qualifications:\n",
    "• Bachelor's or Master's degree in Data Science, Statistics, Computer Science, or related field\n",
    "• 3+ years of experience in data analysis and machine learning\n",
    "• Strong programming skills in Python and R\n",
    "• Experience with SQL and database management\n",
    "• Knowledge of statistical analysis and hypothesis testing\n",
    "• Proficiency with machine learning libraries (scikit-learn, pandas, numpy)\n",
    "• Experience with data visualization tools (matplotlib, seaborn, Tableau)\n",
    "\n",
    "Preferred Qualifications:\n",
    "• Healthcare or medical data analysis experience\n",
    "• Experience with deep learning frameworks (TensorFlow, PyTorch)\n",
    "• Cloud platform experience (AWS, Azure, GCP)\n",
    "• Knowledge of clinical data standards (HL7, FHIR)\n",
    "• Experience with A/B testing and experimental design\n",
    "• Publication record in data science or healthcare\n",
    "\n",
    "Responsibilities:\n",
    "• Analyze large healthcare datasets to extract insights\n",
    "• Build predictive models for patient outcomes\n",
    "• Collaborate with clinical teams to understand data requirements\n",
    "• Develop automated reporting and monitoring systems\n",
    "• Present findings to stakeholders and leadership\n",
    "\n",
    "This role offers the opportunity to make a meaningful impact on patient care through data-driven insights.\n",
    "\"\"\"\n",
    "\n",
    "print(f\"📝 Job description created ({len(job_description)} characters)\")\n",
    "print(\"\\n🎯 Job Focus: Data Scientist - Healthcare Technology\")\n",
    "print(\"💡 Key requirements: Python, R, ML, Healthcare data, 3+ years experience\")\n",
    "\n",
    "# Today's date for resume submission\n",
    "submission_date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "print(f\"📅 Analysis date: {submission_date}\")\n",
    "\n",
    "print(\"\\n✅ Job description ready for relevance scoring!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd7f3efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 STEP 5: ANALYZING A SINGLE RESUME IN DETAIL\n",
      "============================================================\n",
      "📄 Analyzing: 2023-08-28 - Wesley Ordonez Resume Wesley Ordonez 2023 (Data Analytics).pdf\n",
      "⏳ This may take 30-60 seconds for the AI analysis...\n",
      "⏱️  Processing completed in 36.01 seconds\n",
      "📊 Extracted 47 fields from the resume\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Analyze Your First Resume\n",
    "print(\"\\n🔍 STEP 5: ANALYZING A SINGLE RESUME IN DETAIL\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if not resume_paths:\n",
    "    print(\"❌ No resumes available for analysis\")\n",
    "    print(\"💡 Please add resume files to your resume directory first\")\n",
    "else:\n",
    "    # Select the first resume for detailed analysis\n",
    "    test_resume = resume_paths[0]\n",
    "    resume_filename = os.path.basename(test_resume)\n",
    "    \n",
    "    print(f\"📄 Analyzing: {resume_filename}\")\n",
    "    print(\"⏳ This may take 30-60 seconds for the AI analysis...\")\n",
    "    \n",
    "    # Parse the resume\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    \n",
    "    result = parse_single_resume(\n",
    "        client=client,\n",
    "        resume_path=test_resume,\n",
    "        date_of_resume_submission=submission_date,\n",
    "        job_description=job_description\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    print(f\"⏱️  Processing completed in {processing_time:.2f} seconds\")\n",
    "    print(f\"📊 Extracted {len(result)} fields from the resume\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f65dcb89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "👤 STEP 6: BASIC CANDIDATE INFORMATION\n",
      "==================================================\n",
      "📋 PERSONAL DETAILS:\n",
      "   • Name: Wesley Ordoñez\n",
      "   • Email: wesordonez1@gmail.com\n",
      "   • Phone: \n",
      "   • Location: \n",
      "\n",
      "🛠️  SKILLS (14 found):\n",
      "    1. CSS\n",
      "    2. HTML\n",
      "    3. JavaScript\n",
      "    4. Python\n",
      "    5. SQL\n",
      "    6. R\n",
      "    7. Tableau\n",
      "    8. Microsoft Power BI\n",
      "    9. Microsoft Suite\n",
      "   10. Google Suite\n",
      "   ... and 4 more skills\n",
      "\n",
      "🎓 EDUCATION (2 entries):\n",
      "   1. Bachelor of Science in Mechanical Engineering (concentration: Design Engineering)\n",
      "      🏫 Rose-Hulman Institute of Technology (Unknown year)\n",
      "   2. Data Science and Machine Learning, Google Data Analytics Professional Certificate\n",
      "      🏫 Online Coursework (Udemy/Google) (Unknown year)\n",
      "\n",
      "💼 WORK EXPERIENCE (3 positions):\n",
      "   1. Unknown position\n",
      "      🏢 Puerto Rican Cultural Center | ⏱️  Unknown duration\n",
      "   2. Unknown position\n",
      "      🏢 Versatech LLC | ⏱️  Unknown duration\n",
      "   3. Unknown position\n",
      "      🏢 ZF Automotive Group | ⏱️  Unknown duration\n",
      "\n",
      "✅ Basic information extracted successfully!\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Understanding the Basic Information\n",
    "print(\"\\n👤 STEP 6: BASIC CANDIDATE INFORMATION\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "if 'result' in locals():\n",
    "    print(\"📋 PERSONAL DETAILS:\")\n",
    "    print(f\"   • Name: {result.get('name', 'Not found')}\")\n",
    "    print(f\"   • Email: {result.get('email', 'Not found')}\")\n",
    "    print(f\"   • Phone: {result.get('contact_number', 'Not found')}\")\n",
    "    print(f\"   • Location: {result.get('location', 'Not specified')}\")\n",
    "    \n",
    "    # Skills\n",
    "    skills = result.get('skills', [])\n",
    "    if skills:\n",
    "        print(f\"\\n🛠️  SKILLS ({len(skills)} found):\")\n",
    "        # Show first 10 skills\n",
    "        for i, skill in enumerate(skills[:10], 1):\n",
    "            print(f\"   {i:2d}. {skill}\")\n",
    "        if len(skills) > 10:\n",
    "            print(f\"   ... and {len(skills) - 10} more skills\")\n",
    "    \n",
    "    # Education\n",
    "    educations = result.get('educations', [])\n",
    "    if educations:\n",
    "        print(f\"\\n🎓 EDUCATION ({len(educations)} entries):\")\n",
    "        for i, edu in enumerate(educations, 1):\n",
    "            degree = edu.get('degree', 'Unknown degree')\n",
    "            institution = edu.get('institution', 'Unknown institution')\n",
    "            year = edu.get('graduation_year', 'Unknown year')\n",
    "            print(f\"   {i}. {degree}\")\n",
    "            print(f\"      🏫 {institution} ({year})\")\n",
    "    \n",
    "    # Work Experience\n",
    "    work_experiences = result.get('work_experiences', [])\n",
    "    if work_experiences:\n",
    "        print(f\"\\n💼 WORK EXPERIENCE ({len(work_experiences)} positions):\")\n",
    "        for i, work in enumerate(work_experiences[:5], 1):  # Show first 5\n",
    "            title = work.get('title', work.get('position', 'Unknown position'))\n",
    "            company = work.get('company', 'Unknown company')\n",
    "            duration = work.get('duration', 'Unknown duration')\n",
    "            print(f\"   {i}. {title}\")\n",
    "            print(f\"      🏢 {company} | ⏱️  {duration}\")\n",
    "        if len(work_experiences) > 5:\n",
    "            print(f\"   ... and {len(work_experiences) - 5} more positions\")\n",
    "    \n",
    "    print(\"\\n✅ Basic information extracted successfully!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No resume analysis available. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f33280",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔬 STEP 7: EXPLORING THE 21 UNIFIED EXTRACTOR FIELDS\n",
      "=================================================================\n",
      "📊 The unified extractor provides 21 specialized analysis fields:\n",
      "   This replaces multiple separate API calls with one comprehensive analysis\n",
      "\n",
      "📈 EXPERIENCE ANALYSIS:\n",
      "   • Total work experience (years): 5.8\n",
      "   • Relevant work experience (years): 3.7\n",
      "   • Education experience (years): 4.0\n",
      "   • Relevant education (years): 4.0\n",
      "   • Total relevant experience (years): 7.7\n",
      "   • Average company tenure (years): 1.9\n",
      "\n",
      "🎓 EDUCATION ANALYSIS:\n",
      "   • Highest degree attained: Bachelor of Science\n",
      "   • Major/field of study: Mechanical Engineering\n",
      "   • Degree status (completed/in-progress): completed\n",
      "   • School prestige level: medium\n",
      "\n",
      "💼 CAREER ANALYSIS:\n",
      "   • Career seniority level: manager\n",
      "   • Primary job title/role: SBDC Business Advisor and Corridor Manager\n",
      "\n",
      "📞 PROFESSIONAL PROFILES:\n",
      "   • LinkedIn profile URL: Not available\n",
      "   • GitHub profile URL: Not available\n",
      "   • Personal website URL: Not available\n",
      "\n",
      "🎯 RELEVANCE SCORING EXPLANATION:\n",
      "   • Work relevance: 63.8% (3.7/5.8 years)\n",
      "   🟡 Good match with some transferable skills\n",
      "\n",
      "✅ All 21 fields analyzed in a single AI call!\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Understanding the Unified Extractor Fields\n",
    "print(\"\\n🔬 STEP 7: EXPLORING THE 21 UNIFIED EXTRACTOR FIELDS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if 'result' in locals():\n",
    "    print(\"📊 The unified extractor provides 21 specialized analysis fields:\")\n",
    "    print(\"   This replaces multiple separate API calls with one comprehensive analysis\")\n",
    "    \n",
    "    # Group fields by category for better understanding\n",
    "    experience_fields = {\n",
    "        'wyoe': 'Total work experience (years)',\n",
    "        'relevant_wyoe': 'Relevant work experience (years)',\n",
    "        'eyoe': 'Education experience (years)',\n",
    "        'relevant_eyoe': 'Relevant education (years)',\n",
    "        'total_relevant_yoe': 'Total relevant experience (years)',\n",
    "        'average_tenure_at_company_years': 'Average company tenure (years)'\n",
    "    }\n",
    "    \n",
    "    education_fields = {\n",
    "        'highest_degree': 'Highest degree attained',\n",
    "        'highest_degree_major': 'Major/field of study',\n",
    "        'highest_degree_status': 'Degree status (completed/in-progress)',\n",
    "        'highest_degree_school_prestige': 'School prestige level'\n",
    "    }\n",
    "    \n",
    "    career_fields = {\n",
    "        'highest_seniority_level': 'Career seniority level',\n",
    "        'primary_position_title': 'Primary job title/role'\n",
    "    }\n",
    "    \n",
    "    contact_fields = {\n",
    "        'linkedin_url': 'LinkedIn profile URL',\n",
    "        'github_url': 'GitHub profile URL',\n",
    "        'personal_website_url': 'Personal website URL'\n",
    "    }\n",
    "    \n",
    "    # Display experience analysis\n",
    "    print(f\"\\n📈 EXPERIENCE ANALYSIS:\")\n",
    "    for field, description in experience_fields.items():\n",
    "        value = result.get(field, 'Not calculated')\n",
    "        print(f\"   • {description}: {value}\")\n",
    "    \n",
    "    # Display education analysis\n",
    "    print(f\"\\n🎓 EDUCATION ANALYSIS:\")\n",
    "    for field, description in education_fields.items():\n",
    "        value = result.get(field, 'Not found')\n",
    "        print(f\"   • {description}: {value}\")\n",
    "    \n",
    "    # Display career analysis\n",
    "    print(f\"\\n💼 CAREER ANALYSIS:\")\n",
    "    for field, description in career_fields.items():\n",
    "        value = result.get(field, 'Not determined')\n",
    "        print(f\"   • {description}: {value}\")\n",
    "    \n",
    "    # Display contact information\n",
    "    print(f\"\\n📞 PROFESSIONAL PROFILES:\")\n",
    "    for field, description in contact_fields.items():\n",
    "        value = result.get(field, 'Not found')\n",
    "        if value and value != 'Not found':\n",
    "            print(f\"   • {description}: {value}\")\n",
    "        else:\n",
    "            print(f\"   • {description}: Not available\")\n",
    "    \n",
    "    # Relevance calculation explanation\n",
    "    print(f\"\\n🎯 RELEVANCE SCORING EXPLANATION:\")\n",
    "    total_work = result.get('wyoe', 0)\n",
    "    relevant_work = result.get('relevant_wyoe', 0)\n",
    "    if total_work > 0:\n",
    "        relevance_percentage = (relevant_work / total_work) * 100\n",
    "        print(f\"   • Work relevance: {relevance_percentage:.1f}% ({relevant_work:.1f}/{total_work:.1f} years)\")\n",
    "        \n",
    "        if relevance_percentage >= 80:\n",
    "            print(\"   🟢 Excellent match for this role!\")\n",
    "        elif relevance_percentage >= 60:\n",
    "            print(\"   🟡 Good match with some transferable skills\")\n",
    "        elif relevance_percentage >= 40:\n",
    "            print(\"   🟠 Moderate match, may need additional training\")\n",
    "        else:\n",
    "            print(\"   🔴 Limited relevant experience for this specific role\")\n",
    "    \n",
    "    print(f\"\\n✅ All 21 fields analyzed in a single AI call!\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No analysis results available. Run Step 5 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b717564f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📚 STEP 8: PROCESSING MULTIPLE RESUMES SYSTEMATICALLY\n",
      "=================================================================\n",
      "📊 Processing 5 resumes for comprehensive analysis\n",
      "⏳ This will take a few minutes - each resume requires AI analysis\n",
      "🔄 We're using sequential processing for clear step-by-step learning\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parsing resumes: 100%|██████████| 5/5 [02:11<00:00, 26.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Batch processing completed!\n",
      "⏱️  Total time: 131.28 seconds\n",
      "📊 Average per resume: 26.26 seconds\n",
      "📋 Results dataframe shape: (5, 55)\n",
      "📈 Columns available: 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Batch Processing Multiple Resumes (Sequential)\n",
    "print(\"\\n📚 STEP 8: PROCESSING MULTIPLE RESUMES SYSTEMATICALLY\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if len(resume_paths) > 1:\n",
    "    # For tutorial purposes, we'll process a small batch sequentially\n",
    "    # This helps you understand each step without overwhelming output\n",
    "    \n",
    "    batch_size = min(5, len(resume_paths))  # Process up to 5 resumes\n",
    "    batch_resumes = resume_paths[:batch_size]\n",
    "    \n",
    "    print(f\"📊 Processing {batch_size} resumes for comprehensive analysis\")\n",
    "    print(\"⏳ This will take a few minutes - each resume requires AI analysis\")\n",
    "    print(\"🔄 We're using sequential processing for clear step-by-step learning\")\n",
    "    \n",
    "    # Process resumes one by one (sequential, not parallel)\n",
    "    start_time = time.time()\n",
    "    \n",
    "    df = parse_many_resumes(\n",
    "        client=client,\n",
    "        resume_paths=batch_resumes,\n",
    "        date_of_resume_submission=submission_date,\n",
    "        job_description=job_description,\n",
    "        parallel=False,  # Sequential processing for learning\n",
    "        use_tqdm=True   # Show progress bar\n",
    "    )\n",
    "    \n",
    "    processing_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n✅ Batch processing completed!\")\n",
    "    print(f\"⏱️  Total time: {processing_time:.2f} seconds\")\n",
    "    print(f\"📊 Average per resume: {processing_time/batch_size:.2f} seconds\")\n",
    "    print(f\"📋 Results dataframe shape: {df.shape}\")\n",
    "    print(f\"📈 Columns available: {len(df.columns)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"ℹ️  Only one resume available. Add more resumes to try batch processing.\")\n",
    "    # Create a single-row dataframe for consistency\n",
    "    if 'result' in locals():\n",
    "        df = pd.DataFrame([result])\n",
    "        df['parsing_status'] = 'success'\n",
    "        df['filename'] = os.path.basename(test_resume)\n",
    "        print(\"📊 Single resume converted to dataframe format for analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd14120",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📊 STEP 9: UNDERSTANDING BATCH ANALYSIS RESULTS\n",
      "============================================================\n",
      "📈 PROCESSING SUMMARY:\n",
      "   • Total resumes processed: 5\n",
      "   • Successfully analyzed: 5\n",
      "   • Failed to process: 0\n",
      "   • Success rate: 100.0%\n",
      "\n",
      "📊 EXPERIENCE STATISTICS:\n",
      "   • Average total work experience: 8.2 years\n",
      "   • Average relevant work experience: 3.5 years\n",
      "   • Average education experience: 5.0 years\n",
      "   • Overall relevance ratio: 42.1%\n",
      "\n",
      "🎓 EDUCATION DISTRIBUTION:\n",
      "   • Bachelor of Science: 2 candidates (40.0%)\n",
      "   • Master of Science: 2 candidates (40.0%)\n",
      "\n",
      "💼 SENIORITY LEVEL DISTRIBUTION:\n",
      "   • mid-level: 3 candidates (60.0%)\n",
      "   • manager: 1 candidates (20.0%)\n",
      "   • executive: 1 candidates (20.0%)\n",
      "\n",
      "📞 CONTACT INFORMATION AVAILABILITY:\n",
      "   • Email addresses: 5/5 (100.0%)\n",
      "   • LinkedIn profiles: 2/5 (40.0%)\n",
      "   • GitHub profiles: 3/5 (60.0%)\n",
      "\n",
      "🏆 TOP 3 CANDIDATES BY RELEVANCE:\n",
      "   1. Akhil Bukkapuram\n",
      "      🎯 Relevance: 74.2% | 💼 Experience: 3.1 years | 🎓 Master of Science\n",
      "   2. Wesley Ordoñez\n",
      "      🎯 Relevance: 57.6% | 💼 Experience: 5.9 years | 🎓 Bachelor of Science\n",
      "   3. Stefani Sanchez\n",
      "      🎯 Relevance: 44.1% | 💼 Experience: 6.8 years | 🎓 Bachelor of Science\n"
     ]
    }
   ],
   "source": [
    "# Step 9: Analyzing Batch Results\n",
    "print(\"\\n📊 STEP 9: UNDERSTANDING BATCH ANALYSIS RESULTS\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if 'df' in locals():\n",
    "    # Check processing success\n",
    "    total_resumes = len(df)\n",
    "    successful = len(df[df['parsing_status'] == 'success'])\n",
    "    failed = len(df[df['parsing_status'] == 'failed'])\n",
    "    \n",
    "    print(f\"📈 PROCESSING SUMMARY:\")\n",
    "    print(f\"   • Total resumes processed: {total_resumes}\")\n",
    "    print(f\"   • Successfully analyzed: {successful}\")\n",
    "    print(f\"   • Failed to process: {failed}\")\n",
    "    print(f\"   • Success rate: {successful/total_resumes*100:.1f}%\")\n",
    "    \n",
    "    if successful > 0:\n",
    "        successful_df = df[df['parsing_status'] == 'success']\n",
    "        \n",
    "        # Experience statistics\n",
    "        print(f\"\\n📊 EXPERIENCE STATISTICS:\")\n",
    "        avg_total_exp = successful_df['wyoe'].mean()\n",
    "        avg_relevant_exp = successful_df['relevant_wyoe'].mean()\n",
    "        avg_education_exp = successful_df['eyoe'].mean()\n",
    "        \n",
    "        print(f\"   • Average total work experience: {avg_total_exp:.1f} years\")\n",
    "        print(f\"   • Average relevant work experience: {avg_relevant_exp:.1f} years\")\n",
    "        print(f\"   • Average education experience: {avg_education_exp:.1f} years\")\n",
    "        print(f\"   • Overall relevance ratio: {avg_relevant_exp/avg_total_exp*100:.1f}%\")\n",
    "        \n",
    "        # Education distribution\n",
    "        print(f\"\\n🎓 EDUCATION DISTRIBUTION:\")\n",
    "        education_counts = successful_df['highest_degree'].value_counts()\n",
    "        for degree, count in education_counts.items():\n",
    "            percentage = count / len(successful_df) * 100\n",
    "            print(f\"   • {degree}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Seniority distribution\n",
    "        print(f\"\\n💼 SENIORITY LEVEL DISTRIBUTION:\")\n",
    "        seniority_counts = successful_df['highest_seniority_level'].value_counts()\n",
    "        for level, count in seniority_counts.items():\n",
    "            percentage = count / len(successful_df) * 100\n",
    "            print(f\"   • {level}: {count} candidates ({percentage:.1f}%)\")\n",
    "        \n",
    "        # Contact information availability\n",
    "        linkedin_available = successful_df['linkedin_url'].notna().sum()\n",
    "        github_available = successful_df['github_url'].notna().sum()\n",
    "        email_available = successful_df['email'].notna().sum()\n",
    "        \n",
    "        print(f\"\\n📞 CONTACT INFORMATION AVAILABILITY:\")\n",
    "        print(f\"   • Email addresses: {email_available}/{successful} ({email_available/successful*100:.1f}%)\")\n",
    "        print(f\"   • LinkedIn profiles: {linkedin_available}/{successful} ({linkedin_available/successful*100:.1f}%)\")\n",
    "        print(f\"   • GitHub profiles: {github_available}/{successful} ({github_available/successful*100:.1f}%)\")\n",
    "        \n",
    "        # Calculate relevance rankings\n",
    "        successful_df['relevance_percentage'] = (\n",
    "            successful_df['relevant_wyoe'] / successful_df['wyoe'] * 100\n",
    "        ).fillna(0)\n",
    "        \n",
    "        # Show top candidates\n",
    "        top_candidates = successful_df.nlargest(3, 'relevance_percentage')\n",
    "        print(f\"\\n🏆 TOP 3 CANDIDATES BY RELEVANCE:\")\n",
    "        for idx, (_, candidate) in enumerate(top_candidates.iterrows(), 1):\n",
    "            name = candidate.get('name', 'Unknown')\n",
    "            relevance = candidate.get('relevance_percentage', 0)\n",
    "            total_exp = candidate.get('wyoe', 0)\n",
    "            degree = candidate.get('highest_degree', 'Unknown')\n",
    "            print(f\"   {idx}. {name}\")\n",
    "            print(f\"      🎯 Relevance: {relevance:.1f}% | 💼 Experience: {total_exp:.1f} years | 🎓 {degree}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"❌ No successful analyses to display\")\n",
    "        print(\"💡 Check your resume files and job description\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No batch processing results available. Run Step 8 first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6011b402",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "💾 STEP 10: EXPORTING RESULTS FOR YOUR APPLICATIONS\n",
      "=================================================================\n",
      "📊 Complete results exported: tutorial_results/complete_analysis_20250529_205836.csv\n",
      "🎯 Candidate summary exported: tutorial_results/candidate_summary_20250529_205836.csv\n",
      "🔗 JSON format exported: tutorial_results/candidates_20250529_205836.json\n",
      "\n",
      "📁 All files saved to: /Users/samcelarek/Documents/CVInsight/examples/tutorial_results\n",
      "\n",
      "🔗 INTEGRATION EXAMPLES:\n",
      "==============================\n",
      "📊 Loading results in your application:\n",
      "\n",
      "import pandas as pd\n",
      "import json\n",
      "\n",
      "# Load CSV results\n",
      "df = pd.read_csv('tutorial_results/candidate_summary_*.csv')\n",
      "\n",
      "# Load JSON results\n",
      "with open('tutorial_results/candidates_*.json', 'r') as f:\n",
      "    candidates = json.load(f)\n",
      "\n",
      "# Filter high-relevance candidates (70%+ relevant experience)\n",
      "top_candidates = df[df['relevance_percentage'] >= 70]\n",
      "\n",
      "# Extract contact information\n",
      "contacts = top_candidates[['name', 'email', 'linkedin_url']].dropna()\n",
      "\n",
      "🔄 Using in a recruitment pipeline:\n",
      "\n",
      "# Example integration with your HR system\n",
      "for _, candidate in top_candidates.iterrows():\n",
      "    candidate_profile = {\n",
      "        'name': candidate['name'],\n",
      "        'email': candidate['email'],\n",
      "        'relevance_score': candidate['relevance_percentage'],\n",
      "        'experience_years': candidate['all_wyoe'],\n",
      "        'education': candidate['highest_degree'],\n",
      "        'seniority': candidate['highest_seniority_level']\n",
      "    }\n",
      "\n",
      "    # Add to your database or send to your API\n",
      "    add_candidate_to_system(candidate_profile)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 10: Export Results for Integration\n",
    "print(\"\\n💾 STEP 10: EXPORTING RESULTS FOR YOUR APPLICATIONS\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "if 'df' in locals() and len(df) > 0:\n",
    "    # Create results directory\n",
    "    results_dir = Path(\"./tutorial_results\")\n",
    "    results_dir.mkdir(exist_ok=True)\n",
    "    \n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    \n",
    "    # Export complete results\n",
    "    complete_file = results_dir / f\"complete_analysis_{timestamp}.csv\"\n",
    "    df.to_csv(complete_file, index=False)\n",
    "    print(f\"📊 Complete results exported: {complete_file}\")\n",
    "    \n",
    "    # Export successful results only\n",
    "    successful_df = df[df['parsing_status'] == 'success']\n",
    "    if not successful_df.empty:\n",
    "        # Create a summary with key fields\n",
    "        summary_fields = [\n",
    "            'filename', 'name', 'email', 'contact_number',\n",
    "            'wyoe', 'relevant_wyoe', 'eyoe',\n",
    "            'highest_degree', 'highest_seniority_level', 'primary_position_title',\n",
    "            'linkedin_url', 'github_url'\n",
    "        ]\n",
    "        \n",
    "        # Only include fields that exist in the dataframe\n",
    "        available_fields = [field for field in summary_fields if field in successful_df.columns]\n",
    "        summary_df = successful_df[available_fields].copy()\n",
    "        \n",
    "        # Add calculated relevance percentage\n",
    "        summary_df['relevance_percentage'] = (\n",
    "            successful_df['relevant_wyoe'] / successful_df['wyoe'] * 100\n",
    "        ).fillna(0).round(1)\n",
    "        \n",
    "        # Sort by relevance\n",
    "        summary_df = summary_df.sort_values('relevance_percentage', ascending=False)\n",
    "        \n",
    "        summary_file = results_dir / f\"candidate_summary_{timestamp}.csv\"\n",
    "        summary_df.to_csv(summary_file, index=False)\n",
    "        print(f\"🎯 Candidate summary exported: {summary_file}\")\n",
    "        \n",
    "        # Create a JSON export for easy API integration\n",
    "        json_file = results_dir / f\"candidates_{timestamp}.json\"\n",
    "        candidates_json = summary_df.to_dict('records')\n",
    "        with open(json_file, 'w') as f:\n",
    "            json.dump(candidates_json, f, indent=2)\n",
    "        print(f\"🔗 JSON format exported: {json_file}\")\n",
    "    \n",
    "    print(f\"\\n📁 All files saved to: {results_dir.absolute()}\")\n",
    "    \n",
    "    # Show integration examples\n",
    "    print(f\"\\n🔗 INTEGRATION EXAMPLES:\")\n",
    "    print(\"=\" * 30)\n",
    "    \n",
    "    print(\"📊 Loading results in your application:\")\n",
    "    print(\"\"\"\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "# Load CSV results\n",
    "df = pd.read_csv('tutorial_results/candidate_summary_*.csv')\n",
    "\n",
    "# Load JSON results\n",
    "with open('tutorial_results/candidates_*.json', 'r') as f:\n",
    "    candidates = json.load(f)\n",
    "\n",
    "# Filter high-relevance candidates (70%+ relevant experience)\n",
    "top_candidates = df[df['relevance_percentage'] >= 70]\n",
    "\n",
    "# Extract contact information\n",
    "contacts = top_candidates[['name', 'email', 'linkedin_url']].dropna()\n",
    "\"\"\")\n",
    "    \n",
    "    print(\"🔄 Using in a recruitment pipeline:\")\n",
    "    print(\"\"\"\n",
    "# Example integration with your HR system\n",
    "for _, candidate in top_candidates.iterrows():\n",
    "    candidate_profile = {\n",
    "        'name': candidate['name'],\n",
    "        'email': candidate['email'],\n",
    "        'relevance_score': candidate['relevance_percentage'],\n",
    "        'experience_years': candidate['wyoe'],\n",
    "        'education': candidate['highest_degree'],\n",
    "        'seniority': candidate['highest_seniority_level']\n",
    "    }\n",
    "    \n",
    "    # Add to your database or send to your API\n",
    "    add_candidate_to_system(candidate_profile)\n",
    "\"\"\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No results to export. Complete the analysis steps first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e16dd69",
   "metadata": {},
   "source": [
    "## 🎉 Tutorial Complete!\n",
    "\n",
    "### ✅ **What You've Learned:**\n",
    "\n",
    "1. **Setup & Configuration**: How to integrate CVInsight into any Python project\n",
    "2. **Client Initialization**: Setting up the AI-powered analysis engine\n",
    "3. **Single Resume Analysis**: Deep dive into one candidate's profile\n",
    "4. **Unified Extractor**: Understanding all 21 analysis fields\n",
    "5. **Job Relevance Scoring**: How job descriptions affect candidate rankings\n",
    "6. **Batch Processing**: Systematically analyzing multiple resumes\n",
    "7. **Results Interpretation**: Making sense of the analysis data\n",
    "8. **Data Export**: Preparing results for integration into your applications\n",
    "\n",
    "### 🚀 **Key Takeaways:**\n",
    "\n",
    "- **Unified Extractor**: Gets 21 analysis fields in one AI call (75% faster!)\n",
    "- **Job-Specific Relevance**: Candidates are scored against your specific requirements\n",
    "- **Comprehensive Profiling**: Experience, education, skills, seniority, and contact info\n",
    "- **Easy Integration**: Export to CSV, JSON, or direct API integration\n",
    "- **Production Ready**: Handle both single resumes and large batches\n",
    "\n",
    "### 📊 **Understanding the 21 Fields:**\n",
    "\n",
    "**Experience Fields:**\n",
    "- `wyoe`: Total work experience years\n",
    "- `relevant_wyoe`: Work experience relevant to the job\n",
    "- `eyoe`: Education experience years\n",
    "- `relevant_eyoe`: Education relevant to the job\n",
    "- `total_relevant_yoe`: Combined relevant experience\n",
    "- `average_tenure_at_company_years`: Job stability indicator\n",
    "\n",
    "**Education Fields:**\n",
    "- `highest_degree`: Bachelor's, Master's, PhD, etc.\n",
    "- `highest_degree_major`: Field of study\n",
    "- `highest_degree_status`: Completed or in-progress\n",
    "- `highest_degree_school_prestige`: School ranking\n",
    "\n",
    "**Career Fields:**\n",
    "- `highest_seniority_level`: Junior, Mid, Senior, Executive\n",
    "- `primary_position_title`: Main job role\n",
    "\n",
    "**Contact Fields:**\n",
    "- `linkedin_url`, `github_url`, `personal_website_url`: Professional profiles\n",
    "\n",
    "### 💡 **Next Steps:**\n",
    "\n",
    "1. **Try Different Job Descriptions**: See how relevance scores change\n",
    "2. **Process Your Own Resumes**: Upload your actual candidate files\n",
    "3. **Integrate with Your Systems**: Use the exported data in your applications\n",
    "4. **Explore Concurrent Processing**: Try the concurrent analysis demo for speed\n",
    "5. **Production Deployment**: Use the production batch processor for scale\n",
    "\n",
    "### 🔗 **Integration Checklist:**\n",
    "\n",
    "- [ ] Clone CVInsight to your projects directory\n",
    "- [ ] Install dependencies (`pip install -r requirements.txt`)\n",
    "- [ ] Set up your OpenAI API key\n",
    "- [ ] Test with a few sample resumes\n",
    "- [ ] Customize job descriptions for your roles\n",
    "- [ ] Set up automated exports to your systems\n",
    "- [ ] Implement candidate ranking in your workflow\n",
    "\n",
    "**You're now ready to build powerful resume analysis applications with CVInsight!** 🎯\n",
    "\n",
    "---\n",
    "\n",
    "*This tutorial used sequential processing for educational clarity. For production applications with many resumes, consider using the concurrent processing capabilities shown in our other examples.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fafd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "🎯 BONUS: LLM PREDICTION VALIDATION\n",
      "============================================================\n",
      "Let's validate our LLM predictions against known truth values!\n",
      "\n",
      "📊 Loaded truth values for 19 candidates\n",
      "\n",
      "Sample of truth data:\n",
      "               name  LLM Estimated YoE  TYOE  Work Exp Years  Edu Years\n",
      "0         AKASH DAS               4.00   2.5               0        2.5\n",
      "1  Akhil Bukkapuram               4.92   4.5               2        2.5\n",
      "2     AndrewColbert               7.42   7.0               4        3.0\n",
      "3      Brian Warras              10.33   3.1               3        0.1\n",
      "4     Bryan Aguilar               5.42   9.0               6        3.0\n",
      "\n",
      "⚠️ No batch processing results available for validation.\n",
      "Run the batch processing steps above first to generate results for validation.\n",
      "\n",
      "To see validation in action, process some of the resumes that match the truth dataset:\n",
      "Available candidates in truth data:\n",
      "  - AKASH DAS\n",
      "  - Akhil Bukkapuram\n",
      "  - AndrewColbert\n",
      "  - Brian Warras\n",
      "  - Bryan Aguilar\n",
      "  - Doris Fang\n",
      "  - ELIANA MUGAR\n",
      "  - Eric de la Parra\n",
      "  - HARRISON JAMES WEEKS\n",
      "  - John Gianatasio, II.\n"
     ]
    }
   ],
   "source": [
    "# BONUS: LLM Prediction Validation\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"🎯 BONUS: LLM PREDICTION VALIDATION\")\n",
    "print(\"=\"*60)\n",
    "print(\"Let's validate our LLM predictions against known truth values!\")\n",
    "\n",
    "# Load truth values from CSV\n",
    "truth_df = pd.read_csv('/Users/samcelarek/Documents/CVInsight/examples/yoe_truth_values.csv')\n",
    "print(f\"\\n📊 Loaded truth values for {len(truth_df)} candidates\")\n",
    "print(\"\\nSample of truth data:\")\n",
    "print(truth_df[['name', 'LLM Estimated YoE', 'TYOE', 'Work Exp Years', 'Edu Years']].head())\n",
    "\n",
    "# Normalize names for matching (remove spaces, convert to lowercase)\n",
    "def normalize_name(name):\n",
    "    return str(name).replace(' ', '').replace(',', '').replace('.', '').lower().strip()\n",
    "\n",
    "truth_df['normalized_name'] = truth_df['name'].apply(normalize_name)\n",
    "\n",
    "# Check if we have results to validate\n",
    "if 'batch_results' in locals() and batch_results is not None:\n",
    "    print(\"\\n🔍 Validating our tutorial results against actual values...\")\n",
    "    \n",
    "    # Create validation DataFrame\n",
    "    validation_results = []\n",
    "    \n",
    "    for _, candidate in batch_results.iterrows():\n",
    "        if candidate['parsing_status'] == 'success':\n",
    "            candidate_normalized = normalize_name(candidate.get('name', ''))\n",
    "            \n",
    "            # Find matching truth value\n",
    "            truth_match = truth_df[truth_df['normalized_name'] == candidate_normalized]\n",
    "            \n",
    "            if not truth_match.empty:\n",
    "                truth_row = truth_match.iloc[0]\n",
    "                \n",
    "                print(f\"\\n🔍 Validating: {candidate['name']}\")\n",
    "                \n",
    "                # Extract LLM predictions from our processing\n",
    "                llm_work_exp = candidate.get('work_experience_years', 0)\n",
    "                llm_edu_years = candidate.get('education_years', 0)\n",
    "                llm_total_yoe = llm_work_exp + llm_edu_years  # Calculate LLM total from components\n",
    "                \n",
    "                # Extract truth values\n",
    "                actual_work_exp = truth_row['Work Exp Years']\n",
    "                actual_edu_years = truth_row['Edu Years']\n",
    "                actual_total_yoe = truth_row['TYOE']\n",
    "                \n",
    "                # Calculate errors (comparing LLM predictions vs truth values)\n",
    "                work_exp_error = abs(llm_work_exp - actual_work_exp)\n",
    "                edu_years_error = abs(llm_edu_years - actual_edu_years)\n",
    "                total_yoe_error = abs(llm_total_yoe - actual_total_yoe)\n",
    "                \n",
    "                print(f\"  Work Experience: LLM={llm_work_exp}, Actual={actual_work_exp}, Error={work_exp_error:.1f}\")\n",
    "                print(f\"  Education Years: LLM={llm_edu_years}, Actual={actual_edu_years}, Error={edu_years_error:.1f}\")\n",
    "                print(f\"  Total YoE: LLM Calc.={llm_total_yoe}, Actual={actual_total_yoe}, Error={total_yoe_error:.1f}\")\n",
    "                \n",
    "                validation_results.append({\n",
    "                    'name': candidate['name'],\n",
    "                    'llm_work_exp': llm_work_exp,\n",
    "                    'actual_work_exp': actual_work_exp,\n",
    "                    'work_exp_error': work_exp_error,\n",
    "                    'llm_edu_years': llm_edu_years,\n",
    "                    'actual_edu_years': actual_edu_years,\n",
    "                    'edu_years_error': edu_years_error,\n",
    "                    'llm_total_yoe': llm_total_yoe,\n",
    "                    'actual_total_yoe': actual_total_yoe,\n",
    "                    'total_yoe_error': total_yoe_error\n",
    "                })\n",
    "    \n",
    "    if validation_results:\n",
    "        validation_df = pd.DataFrame(validation_results)\n",
    "        \n",
    "        print(f\"\\n\\n✅ VALIDATION COMPLETE: Matched {len(validation_df)} candidates\")\n",
    "        print(\"\\n📊 VALIDATION SUMMARY:\")\n",
    "        print(\"-\" * 40)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mean_work_error = validation_df['work_exp_error'].mean()\n",
    "        mean_edu_error = validation_df['edu_years_error'].mean()\n",
    "        mean_yoe_error = validation_df['total_yoe_error'].mean()\n",
    "        \n",
    "        print(f\"Mean Work Experience Error: {mean_work_error:.2f} years\")\n",
    "        print(f\"Mean Education Years Error: {mean_edu_error:.2f} years\")\n",
    "        print(f\"Mean Total YoE Error: {mean_yoe_error:.2f} years\")\n",
    "        \n",
    "        # Accuracy assessment\n",
    "        work_within_1_year = len(validation_df[validation_df['work_exp_error'] <= 1]) / len(validation_df) * 100\n",
    "        edu_within_1_year = len(validation_df[validation_df['edu_years_error'] <= 1]) / len(validation_df) * 100\n",
    "        yoe_within_2_years = len(validation_df[validation_df['total_yoe_error'] <= 2]) / len(validation_df) * 100\n",
    "        \n",
    "        print(f\"\\n🎯 ACCURACY METRICS:\")\n",
    "        print(f\"Work Experience within 1 year: {work_within_1_year:.1f}%\")\n",
    "        print(f\"Education Years within 1 year: {edu_within_1_year:.1f}%\")\n",
    "        print(f\"Total YoE within 2 years: {yoe_within_2_years:.1f}%\")\n",
    "        \n",
    "        # Show best and worst predictions\n",
    "        print(\"\\n✅ MOST ACCURATE PREDICTIONS:\")\n",
    "        best_predictions = validation_df.nsmallest(3, 'total_yoe_error')\n",
    "        for _, row in best_predictions.iterrows():\n",
    "            print(f\"  {row['name']}: Total YoE Error = {row['total_yoe_error']:.1f} years\")\n",
    "        \n",
    "        print(\"\\n❌ LEAST ACCURATE PREDICTIONS:\")\n",
    "        worst_predictions = validation_df.nlargest(3, 'total_yoe_error')\n",
    "        for _, row in worst_predictions.iterrows():\n",
    "            print(f\"  {row['name']}: Total YoE Error = {row['total_yoe_error']:.1f} years\")\n",
    "        \n",
    "        # Save validation results\n",
    "        output_path = './tutorial_results/tutorial_validation_results.csv'\n",
    "        validation_df.to_csv(output_path, index=False)\n",
    "        print(f\"\\n💾 Validation results saved to: {output_path}\")\n",
    "        \n",
    "        print(\"\\n🎆 TUTORIAL COMPLETE!\")\n",
    "        print(\"You've learned how to:\")\n",
    "        print(\"✓ Process resumes with CVInsight\")\n",
    "        print(\"✓ Analyze and interpret results\")\n",
    "        print(\"✓ Validate LLM predictions against truth values\")\n",
    "        print(\"✓ Export data for integration\")\n",
    "    else:\n",
    "        print(\"\\n⚠️ No matching candidates found for validation\")\n",
    "        print(\"This might happen if the resumes processed don't match the truth dataset.\")\n",
    "else:\n",
    "    print(\"\\n⚠️ No batch processing results available for validation.\")\n",
    "    print(\"Run the batch processing steps above first to generate results for validation.\")\n",
    "    print(\"\\nTo see validation in action, process some of the resumes that match the truth dataset:\")\n",
    "    print(\"Available candidates in truth data:\")\n",
    "    for name in truth_df['name'].head(10):\n",
    "        print(f\"  - {name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "resume_parsing",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
